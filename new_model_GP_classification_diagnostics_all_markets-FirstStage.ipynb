{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 'AL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_symptoms_train = 'comments/raw_comments/agent_comments_'+state+\\\n",
    "                        '_filtered_final_joined_selected_columns_use_max_scale_one_df_train.fea'\n",
    "\n",
    "noun_sentence_state_train = pd.read_feather(file_symptoms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_symptoms_test = 'comments/raw_comments/agent_comments_'+state+\\\n",
    "                        '_filtered_final_joined_selected_columns_use_max_scale_one_df_test.fea'\n",
    "noun_sentence_state_test = pd.read_feather(file_symptoms_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_sentence_state_test_transdate_train = noun_sentence_state_train.groupby('Transdate').mean()[['avmerror']].reset_index()\n",
    "noun_sentence_state_test_transdate_train = noun_sentence_state_test_transdate_train.rename(columns={\"avmerror\": \"avmerror_mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_sentence_state_test_transdate_test = noun_sentence_state_test.groupby('Transdate').mean()[['avmerror']].reset_index()\n",
    "noun_sentence_state_test_transdate_test = noun_sentence_state_test_transdate_test.rename(columns={\"avmerror\": \"avmerror_mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_sentence_state_train = noun_sentence_state_train.merge(noun_sentence_state_test_transdate_train,\n",
    "                                                         how='left', left_on='Transdate', right_on='Transdate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_sentence_state_test = noun_sentence_state_test.merge(noun_sentence_state_test_transdate_test,\n",
    "                                                         how='left', left_on='Transdate', right_on='Transdate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selcted_columns = ['cbsa', 'Transdate', \n",
    "       'cj_living_area', 'census_tract', 'zip', \n",
    "       'avmValue', \n",
    "       'AVM_Error_Indicators_0', 'AVM_Error_Indicators_1',\n",
    "       'AVM_Error_Indicators_2', 'AVM_Error_Indicators_3',\n",
    "       'AVM_Error_Indicators_4', 'AVM_Error_Indicators_5',\n",
    "       'AVM_Error_Indicators_6', 'AVM_Error_Indicators_7',\n",
    "       'AVM_Error_Indicators_8', 'AVM_Error_Indicators_9',\n",
    "       'AVM_Error_Indicators_10', 'AVM_Error_Indicators_11',\n",
    "       'AVM_Error_Indicators_scale', 'AVM_Error_Indicators_scale_inverse',\n",
    "       'Listing_Error_Indicators_0', 'Listing_Error_Indicators_1',\n",
    "       'Listing_Error_Indicators_2', 'Listing_Error_Indicators_3',\n",
    "       'Listing_Error_Indicators_4', 'Listing_Error_Indicators_5',\n",
    "       'Listing_Error_Indicators_6', 'Listing_Error_Indicators_7',\n",
    "       'Listing_Error_Indicators_8', 'Listing_Error_Indicators_9',\n",
    "       'Listing_Error_Indicators_10', 'Listing_Error_Indicators_11',\n",
    "       'AVM_Error_Indicators_0_max_value',\n",
    "       'AVM_Error_Indicators_0_min_value',\n",
    "       'AVM_Error_Indicators_0_max_indicator',\n",
    "       'AVM_Error_Indicators_0_min_indicator',\n",
    "       'AVM_Error_Indicators_0_diff_indicator',\n",
    "       'AVM_Error_Indicators_0_diff_value', 'AVM_Error_Indicators_0_mean','avmerror_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selcted_columns = selcted_columns + list(noun_sentence_state_train.columns[51:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms_df = noun_sentence_state_train.loc[:,selcted_columns]\n",
    "symptoms_df_test = noun_sentence_state_test.loc[:,selcted_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_sentence_state_train['category_predictand'] = 0\n",
    "noun_sentence_state_train.loc[noun_sentence_state_train['avmerror']>=0.,'category_predictand'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_sentence_state_test['category_predictand'] = 0\n",
    "noun_sentence_state_test.loc[noun_sentence_state_test['avmerror']>=0.,'category_predictand'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictors = symptoms_df.to_numpy()\n",
    "X_test = symptoms_df_test.to_numpy()\n",
    "X_train = Predictors\n",
    "predictand = noun_sentence_state_train.category_predictand.values\n",
    "y_train = predictand\n",
    "y_test = noun_sentence_state_test.category_predictand.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
    "                              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_params(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = model.predict(X_test)\n",
    "predictions_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_prob = model.predict_proba(X_test)\n",
    "predictions_train_prob = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train = confusion_matrix(y_train, predictions_train)\n",
    "print(cm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_accuracy_score(y_train, predictions_train_prob, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_train, predictions_train, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_train, predictions_train, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train, predictions_train, average= 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = confusion_matrix(y_test, predictions_test)\n",
    "print(cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_accuracy_score(y_test, predictions_test_prob, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [100]\n",
    "# Number of features to consider at every split\n",
    "max_features = [ 100, 150, 200]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [40, 50, 60]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [10, 20, 30]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [15, 20, 25]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 5, cv = 3, verbose=1, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "#base_model.fit(train_features, train_labels)\n",
    "#base_accuracy = evaluate(base_model, test_features, test_labels)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "best_random_model_prediction = best_random.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, best_random_model_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = 150000  # Samples used for training the models\n",
    "X_trainR, X_testR, y_trainR, y_testR = train_test_split(\n",
    "    Predictors,\n",
    "    Series,\n",
    "    shuffle=False,\n",
    "    test_size=len(Predictors) - train_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRegression = [RandomForestRegressor(n_estimators = 100,  min_samples_leaf=20, \n",
    "                              max_features = 150, max_depth=50),\n",
    "                       RandomForestRegressor(n_estimators = 100,  min_samples_leaf=20, \n",
    "                              max_features = 150, max_depth=50),\n",
    "                       RandomForestRegressor(n_estimators = 100,  min_samples_leaf=20, \n",
    "                              max_features = 150, max_depth=50)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(i)\n",
    "    y_trainR_temp = y_trainR[np.where(y_train == i)[0]]\n",
    "    X_trainR_temp = X_trainR[np.where(y_train == i)[0],:]\n",
    "    \n",
    "    y_testR_temp = y_testR[np.where(y_test == i)[0]]\n",
    "    X_testR_temp = X_testR[np.where(y_test == i)[0],:]    \n",
    "    \n",
    "    modelRegression[i].fit(X_trainR_temp, y_trainR_temp)\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = symptoms_dataframe_ri.copy()\n",
    "\n",
    "for i in range(3):\n",
    "    print(i)\n",
    "    y_trainR_temp = y_trainR[np.where(y_train == i)[0]]\n",
    "    X_trainR_temp = X_trainR[np.where(y_train == i)[0],:]\n",
    "    \n",
    "    y_testR_temp = y_testR[np.where(y_test == i)[0]]\n",
    "    X_testR_temp = X_testR[np.where(y_test == i)[0],:]    \n",
    "    \n",
    "    predictions_testR = modelRegression[i].predict(X_testR_temp)\n",
    "    predictions_trainR = modelRegression[i].predict(X_trainR_temp)\n",
    "\n",
    "    avmValue_test = df['avmValue'].values[train_samples:][np.where(y_test == i)[0]]\n",
    "    avmValue_train = df['avmValue'].values[:train_samples][np.where(y_train == i)[0]]\n",
    "    \n",
    "    predictions_test_valueR = avmValue_test/(1-predictions_testR)\n",
    "    predictions_train_valueR = avmValue_train/(1-predictions_trainR)\n",
    "    \n",
    "    print('') \n",
    "    fig = plt.figure()\n",
    "    plt.plot(predictions_test_valueR, \n",
    "         df['Transprice'].values[train_samples:][np.where(y_test == i)[0]],'o')\n",
    "    plt.plot(predictions_test_valueR,predictions_test_valueR)\n",
    "    \n",
    "    print('') \n",
    "    print('Testing')\n",
    "    print(np.mean(np.abs(df['Transprice'].values[train_samples:][np.where(y_test == i)[0]]-predictions_test_valueR)/\\\n",
    "              (df['Transprice'].values[train_samples:][np.where(y_test == i)[0]])))\n",
    "    print(np.mean(np.abs(df['Transprice'].values[train_samples:][np.where(y_test == i)[0]] - avmValue_test)/\\\n",
    "                  (df['Transprice'].values[train_samples:][np.where(y_test == i)[0]])))\n",
    "    \n",
    "    print('') \n",
    "    print('Training') \n",
    "    print(np.mean(np.abs(df['Transprice'].values[:train_samples][np.where(y_train == i)[0]]-predictions_train_valueR)/\\\n",
    "              (df['Transprice'].values[:train_samples][np.where(y_train == i)[0]])))\n",
    "    print(np.mean(np.abs(df['Transprice'].values[:train_samples][np.where(y_train == i)[0]] - avmValue_train)/\\\n",
    "                  (df['Transprice'].values[:train_samples][np.where(y_train == i)[0]])))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(predictions_train,y_train,bins=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = symptoms_dataframe_ri.copy()\n",
    "avmerror_test = df['avmValue'].values[train_samples:]\n",
    "avmerror_train = df['avmValue'].values[:train_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_value = avmerror_test[np.where(y_train == i)]/(1-predictions_test)\n",
    "predictions_train_value = avmerror_train[np.where(y_train == i)]/(1-predictions_train)\n",
    "#predictions_train_value = df['avmValue'].values/(1-Predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series_disctzd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(np.abs(df['Transprice'].values[:train_samples]-predictions_train_value)/\\\n",
    "              (df['Transprice'].values[:train_samples])))\n",
    "print(np.mean(np.abs(df['Transprice'].values[:train_samples]- Series_disctzd[:train_samples])/\\\n",
    "              (df['Transprice'].values[:train_samples])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(np.abs(df['Transprice'].values[train_samples:]-predictions_test_value)/\\\n",
    "              (df['Transprice'].values[train_samples:])))\n",
    "print(np.mean(np.abs(df['Transprice'].values[train_samples:]- Series_disctzd[train_samples:])/\\\n",
    "              (df['Transprice'].values[train_samples:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predictions_train_value,df['Transprice'].values[:train_samples],'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "features = predictor_columns\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "features = predictor_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(features[indices][-250:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[features[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "filename = 'RF_newmodel_01_3mins.sav'\n",
    "joblib.dump(model,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
