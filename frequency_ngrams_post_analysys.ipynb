{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-23 14:32:38,118 loading file /home/cdsw/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    }
   ],
   "source": [
    "import nlp_pandas_functions as npf\n",
    "#dir(npf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install pyarrow\n",
    "#pip3 install spacy\n",
    "#pip3 install wordcloud\n",
    "#pip3 install nltk\n",
    "#pip3 install sklearn\n",
    "#pip3 install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_state = 'GA'\n",
    "file = 'agent_comments_sales_'+str_state\n",
    "#file = 'agent_comments_testdf'\n",
    "#READ THE SALES DATA - STATE\n",
    "df_sales = pd.read_feather(file + '_withembeddings.fea')\n",
    "#df_sales = pd.read_feather(file+'_processed.fea')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_save = df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = df_sales_save#.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listingid</th>\n",
       "      <th>asgpropid</th>\n",
       "      <th>qtr</th>\n",
       "      <th>tax_year</th>\n",
       "      <th>cbsa_div</th>\n",
       "      <th>cbsa</th>\n",
       "      <th>state</th>\n",
       "      <th>Transdate</th>\n",
       "      <th>Transprice</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>clean_publicremarks_stemmed_additional_words_vaderpolarity</th>\n",
       "      <th>clean_publicremarks_lemmatized_vaderpolarity</th>\n",
       "      <th>clean_publicremarks_lemmatized_additional_words_vaderpolarity</th>\n",
       "      <th>sentence_composition</th>\n",
       "      <th>publicremarks_embeddings</th>\n",
       "      <th>clean_publicremarks_embeddings</th>\n",
       "      <th>clean_publicremarks_additional_words_embeddings</th>\n",
       "      <th>clean_publicremarks_nopunct_embeddings</th>\n",
       "      <th>clean_publicremarks_stemmed_embeddings</th>\n",
       "      <th>clean_publicremarks_lemmatized_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>226661582</td>\n",
       "      <td>27649366.0</td>\n",
       "      <td>202008</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>23580</td>\n",
       "      <td>23580</td>\n",
       "      <td>GA</td>\n",
       "      <td>20200811</td>\n",
       "      <td>359000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.4939, 'neg': 0.0, 'neu': 0.954,...</td>\n",
       "      <td>{'compound': 0.9578, 'neg': 0.0, 'neu': 0.786,...</td>\n",
       "      <td>{'compound': 0.93, 'neg': 0.0, 'neu': 0.81, 'p...</td>\n",
       "      <td>[55.00000000000001, 13.750000000000002, 17.5, ...</td>\n",
       "      <td>[-0.018459855, -0.023812085, -0.043892566, -0....</td>\n",
       "      <td>[-0.051987942, -0.054606345, -0.0580922, -0.03...</td>\n",
       "      <td>[-0.05043851, -0.056709077, -0.055227116, -0.0...</td>\n",
       "      <td>[-0.051987942, -0.054606345, -0.0580922, -0.03...</td>\n",
       "      <td>[-0.038664196, -0.05890688, -0.06525755, -0.02...</td>\n",
       "      <td>[-0.04986923, -0.05113033, -0.060150877, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>226786904</td>\n",
       "      <td>27628370.0</td>\n",
       "      <td>202008</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>29300</td>\n",
       "      <td>29300</td>\n",
       "      <td>GA</td>\n",
       "      <td>20200925</td>\n",
       "      <td>265000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.9686, 'neg': 0.0, 'neu': 0.799,...</td>\n",
       "      <td>{'compound': 0.9875, 'neg': 0.014, 'neu': 0.70...</td>\n",
       "      <td>{'compound': 0.9844, 'neg': 0.016, 'neu': 0.70...</td>\n",
       "      <td>[60.18518518518518, 13.88888888888889, 18.5185...</td>\n",
       "      <td>[-0.060909368, -0.044562507, -0.048587322, -0....</td>\n",
       "      <td>[-0.06049352, -0.05438737, -0.048537098, -0.05...</td>\n",
       "      <td>[-0.059828583, -0.05020684, -0.046291806, -0.0...</td>\n",
       "      <td>[-0.06049352, -0.05438737, -0.048537098, -0.05...</td>\n",
       "      <td>[-0.065291695, -0.06122866, -0.04930517, 0.006...</td>\n",
       "      <td>[-0.060174935, -0.05459462, -0.045611445, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>226142320</td>\n",
       "      <td>27963359.0</td>\n",
       "      <td>202005</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>27600</td>\n",
       "      <td>27600</td>\n",
       "      <td>GA</td>\n",
       "      <td>20200624</td>\n",
       "      <td>239900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.3182, 'neg': 0.0, 'neu': 0.957,...</td>\n",
       "      <td>{'compound': 0.8074, 'neg': 0.0, 'neu': 0.858,...</td>\n",
       "      <td>{'compound': 0.8074, 'neg': 0.0, 'neu': 0.855,...</td>\n",
       "      <td>[60.37735849056604, 9.433962264150944, 24.5283...</td>\n",
       "      <td>[0.051360507, -0.007422204, -0.054501485, -0.0...</td>\n",
       "      <td>[-0.015618877, -0.03321094, -0.064131856, -0.0...</td>\n",
       "      <td>[-0.011177328, -0.034213364, -0.06423391, -0.0...</td>\n",
       "      <td>[-0.015618877, -0.03321094, -0.064131856, -0.0...</td>\n",
       "      <td>[-0.026406875, -0.061117634, -0.071621135, -0....</td>\n",
       "      <td>[-0.026331514, -0.048204094, -0.06567335, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>226738459</td>\n",
       "      <td>27516267.0</td>\n",
       "      <td>202008</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>29300</td>\n",
       "      <td>29300</td>\n",
       "      <td>GA</td>\n",
       "      <td>20200713</td>\n",
       "      <td>130900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...</td>\n",
       "      <td>{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...</td>\n",
       "      <td>{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...</td>\n",
       "      <td>[53.84615384615385, 7.6923076923076925, 38.461...</td>\n",
       "      <td>[-0.020899976, 0.016856506, -0.011256389, -0.0...</td>\n",
       "      <td>[-0.028272344, -0.005281781, -0.0073222406, -0...</td>\n",
       "      <td>[0.0036934454, 0.047616564, -0.0056924997, 0.0...</td>\n",
       "      <td>[-0.028272344, -0.005281781, -0.0073222406, -0...</td>\n",
       "      <td>[-0.050069433, 0.007041185, -0.033259477, -0.0...</td>\n",
       "      <td>[-0.028272344, -0.005281781, -0.0073222406, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>226850183</td>\n",
       "      <td>27791872.0</td>\n",
       "      <td>202008</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>23580</td>\n",
       "      <td>23580</td>\n",
       "      <td>GA</td>\n",
       "      <td>20200702</td>\n",
       "      <td>406000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.2023, 'neg': 0.0, 'neu': 0.969,...</td>\n",
       "      <td>{'compound': 0.802, 'neg': 0.0, 'neu': 0.876, ...</td>\n",
       "      <td>{'compound': 0.6908, 'neg': 0.0, 'neu': 0.908,...</td>\n",
       "      <td>[65.57377049180327, 13.114754098360656, 11.475...</td>\n",
       "      <td>[-0.047313046, 0.00859506, -0.04837404, -0.052...</td>\n",
       "      <td>[-0.055047132, -0.031499583, -0.055006824, -0....</td>\n",
       "      <td>[-0.053909175, -0.025725972, -0.05363282, -0.0...</td>\n",
       "      <td>[-0.055047132, -0.031499583, -0.055006824, -0....</td>\n",
       "      <td>[-0.061100535, -0.05123385, -0.067388244, -0.0...</td>\n",
       "      <td>[-0.054386344, -0.04275706, -0.052802, -0.0314...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>633866</td>\n",
       "      <td>77898274</td>\n",
       "      <td>106321613.0</td>\n",
       "      <td>200708</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>27600</td>\n",
       "      <td>27600</td>\n",
       "      <td>GA</td>\n",
       "      <td>20070719</td>\n",
       "      <td>163900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.5574, 'neg': 0.0, 'neu': 0.839,...</td>\n",
       "      <td>{'compound': 0.5574, 'neg': 0.0, 'neu': 0.85, ...</td>\n",
       "      <td>{'compound': 0.5574, 'neg': 0.0, 'neu': 0.839,...</td>\n",
       "      <td>[57.14285714285714, 17.857142857142858, 14.285...</td>\n",
       "      <td>[-0.051895734, -0.034251053, 0.033765092, -0.0...</td>\n",
       "      <td>[-0.060446255, -0.039059404, -0.010817213, 0.0...</td>\n",
       "      <td>[-0.05962046, -0.036440928, -0.007841245, 0.01...</td>\n",
       "      <td>[-0.060446255, -0.039059404, -0.010817213, 0.0...</td>\n",
       "      <td>[-0.054491606, -0.042947643, -0.054990385, 0.0...</td>\n",
       "      <td>[-0.0584565, -0.023282561, -0.03466136, 0.0145...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>633867</td>\n",
       "      <td>77863520</td>\n",
       "      <td>131534737.0</td>\n",
       "      <td>200705</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>23580</td>\n",
       "      <td>23580</td>\n",
       "      <td>GA</td>\n",
       "      <td>20070430</td>\n",
       "      <td>292300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.6249, 'neg': 0.0, 'neu': 0.859,...</td>\n",
       "      <td>{'compound': 0.8316, 'neg': 0.0, 'neu': 0.762,...</td>\n",
       "      <td>{'compound': 0.8316, 'neg': 0.0, 'neu': 0.755,...</td>\n",
       "      <td>[48.148148148148145, 11.11111111111111, 25.925...</td>\n",
       "      <td>[-0.014205737, -0.003559438, -0.062112767, -0....</td>\n",
       "      <td>[-0.026727155, -0.030834762, -0.06737272, -0.0...</td>\n",
       "      <td>[-0.024440665, -0.016382039, -0.067579195, -0....</td>\n",
       "      <td>[-0.026727155, -0.030834762, -0.06737272, -0.0...</td>\n",
       "      <td>[0.0006334283, 0.008003559, -0.046898626, -0.0...</td>\n",
       "      <td>[-0.019545235, -0.03768261, -0.06952793, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>633868</td>\n",
       "      <td>77900119</td>\n",
       "      <td>131589092.0</td>\n",
       "      <td>200708</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>23580</td>\n",
       "      <td>23580</td>\n",
       "      <td>GA</td>\n",
       "      <td>20070831</td>\n",
       "      <td>181000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.7506, 'neg': 0.0, 'neu': 0.738,...</td>\n",
       "      <td>{'compound': 0.8779, 'neg': 0.0, 'neu': 0.605,...</td>\n",
       "      <td>{'compound': 0.8779, 'neg': 0.0, 'neu': 0.59, ...</td>\n",
       "      <td>[52.38095238095239, 9.523809523809524, 38.0952...</td>\n",
       "      <td>[-0.019684939, 0.010117671, -0.023263527, -0.0...</td>\n",
       "      <td>[-0.04207756, -0.019777237, -0.061898522, 0.02...</td>\n",
       "      <td>[-0.03966484, -0.010800129, -0.06834481, 0.037...</td>\n",
       "      <td>[-0.04207756, -0.019777237, -0.061898522, 0.02...</td>\n",
       "      <td>[-0.016838605, -0.0041591953, -0.048585974, 0....</td>\n",
       "      <td>[-0.03365848, -0.030594666, -0.061209537, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>633869</td>\n",
       "      <td>77861631</td>\n",
       "      <td>131589103.0</td>\n",
       "      <td>200702</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>23580</td>\n",
       "      <td>23580</td>\n",
       "      <td>GA</td>\n",
       "      <td>20070214</td>\n",
       "      <td>179800.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.3612, 'neg': 0.0, 'neu': 0.909,...</td>\n",
       "      <td>{'compound': 0.5106, 'neg': 0.0, 'neu': 0.887,...</td>\n",
       "      <td>{'compound': 0.5106, 'neg': 0.0, 'neu': 0.883,...</td>\n",
       "      <td>[60.0, 6.666666666666667, 33.33333333333333, 0...</td>\n",
       "      <td>[-0.021003596, -0.033517517, -0.030121898, -0....</td>\n",
       "      <td>[-0.010718957, -0.050030287, -0.042237516, -0....</td>\n",
       "      <td>[0.0027086844, -0.048275027, -0.04004254, -0.0...</td>\n",
       "      <td>[-0.010718957, -0.050030287, -0.042237516, -0....</td>\n",
       "      <td>[0.018240895, -0.050512295, -0.07150624, -0.04...</td>\n",
       "      <td>[-0.0015628912, -0.04374602, -0.05042092, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>633870</td>\n",
       "      <td>77883696</td>\n",
       "      <td>131589105.0</td>\n",
       "      <td>200705</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>23580</td>\n",
       "      <td>23580</td>\n",
       "      <td>GA</td>\n",
       "      <td>20070420</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.8481, 'neg': 0.0, 'neu': 0.767,...</td>\n",
       "      <td>{'compound': 0.9287, 'neg': 0.0, 'neu': 0.655,...</td>\n",
       "      <td>{'compound': 0.9287, 'neg': 0.0, 'neu': 0.646,...</td>\n",
       "      <td>[56.666666666666664, 16.666666666666664, 26.66...</td>\n",
       "      <td>[-0.06345986, -0.008993911, -0.038106047, -0.0...</td>\n",
       "      <td>[-0.0641096, -0.056962736, -0.0384166, -0.0619...</td>\n",
       "      <td>[-0.05954439, -0.059571687, -0.03887053, -0.05...</td>\n",
       "      <td>[-0.0641096, -0.056962736, -0.0384166, -0.0619...</td>\n",
       "      <td>[-0.05678726, -0.039550208, -0.022041079, -0.0...</td>\n",
       "      <td>[-0.060876556, -0.061023917, -0.039990727, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633871 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        listingid    asgpropid     qtr  tax_year cbsa_div   cbsa state  \\\n",
       "0       226661582   27649366.0  202008    2020.0    23580  23580    GA   \n",
       "1       226786904   27628370.0  202008    2020.0    29300  29300    GA   \n",
       "2       226142320   27963359.0  202005    2020.0    27600  27600    GA   \n",
       "3       226738459   27516267.0  202008    2020.0    29300  29300    GA   \n",
       "4       226850183   27791872.0  202008    2020.0    23580  23580    GA   \n",
       "...           ...          ...     ...       ...      ...    ...   ...   \n",
       "633866   77898274  106321613.0  200708    2013.0    27600  27600    GA   \n",
       "633867   77863520  131534737.0  200705    2013.0    23580  23580    GA   \n",
       "633868   77900119  131589092.0  200708    2013.0    23580  23580    GA   \n",
       "633869   77861631  131589103.0  200702    2013.0    23580  23580    GA   \n",
       "633870   77883696  131589105.0  200705    2013.0    23580  23580    GA   \n",
       "\n",
       "        Transdate  Transprice  bedrooms  ...  \\\n",
       "0        20200811    359000.0       4.0  ...   \n",
       "1        20200925    265000.0       4.0  ...   \n",
       "2        20200624    239900.0       4.0  ...   \n",
       "3        20200713    130900.0       3.0  ...   \n",
       "4        20200702    406000.0       4.0  ...   \n",
       "...           ...         ...       ...  ...   \n",
       "633866   20070719    163900.0       NaN  ...   \n",
       "633867   20070430    292300.0       3.0  ...   \n",
       "633868   20070831    181000.0       3.0  ...   \n",
       "633869   20070214    179800.0       3.0  ...   \n",
       "633870   20070420    185000.0       3.0  ...   \n",
       "\n",
       "        clean_publicremarks_stemmed_additional_words_vaderpolarity  \\\n",
       "0       {'compound': 0.4939, 'neg': 0.0, 'neu': 0.954,...            \n",
       "1       {'compound': 0.9686, 'neg': 0.0, 'neu': 0.799,...            \n",
       "2       {'compound': 0.3182, 'neg': 0.0, 'neu': 0.957,...            \n",
       "3       {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...            \n",
       "4       {'compound': 0.2023, 'neg': 0.0, 'neu': 0.969,...            \n",
       "...                                                   ...            \n",
       "633866  {'compound': 0.5574, 'neg': 0.0, 'neu': 0.839,...            \n",
       "633867  {'compound': 0.6249, 'neg': 0.0, 'neu': 0.859,...            \n",
       "633868  {'compound': 0.7506, 'neg': 0.0, 'neu': 0.738,...            \n",
       "633869  {'compound': 0.3612, 'neg': 0.0, 'neu': 0.909,...            \n",
       "633870  {'compound': 0.8481, 'neg': 0.0, 'neu': 0.767,...            \n",
       "\n",
       "             clean_publicremarks_lemmatized_vaderpolarity  \\\n",
       "0       {'compound': 0.9578, 'neg': 0.0, 'neu': 0.786,...   \n",
       "1       {'compound': 0.9875, 'neg': 0.014, 'neu': 0.70...   \n",
       "2       {'compound': 0.8074, 'neg': 0.0, 'neu': 0.858,...   \n",
       "3       {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...   \n",
       "4       {'compound': 0.802, 'neg': 0.0, 'neu': 0.876, ...   \n",
       "...                                                   ...   \n",
       "633866  {'compound': 0.5574, 'neg': 0.0, 'neu': 0.85, ...   \n",
       "633867  {'compound': 0.8316, 'neg': 0.0, 'neu': 0.762,...   \n",
       "633868  {'compound': 0.8779, 'neg': 0.0, 'neu': 0.605,...   \n",
       "633869  {'compound': 0.5106, 'neg': 0.0, 'neu': 0.887,...   \n",
       "633870  {'compound': 0.9287, 'neg': 0.0, 'neu': 0.655,...   \n",
       "\n",
       "        clean_publicremarks_lemmatized_additional_words_vaderpolarity  \\\n",
       "0       {'compound': 0.93, 'neg': 0.0, 'neu': 0.81, 'p...               \n",
       "1       {'compound': 0.9844, 'neg': 0.016, 'neu': 0.70...               \n",
       "2       {'compound': 0.8074, 'neg': 0.0, 'neu': 0.855,...               \n",
       "3       {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...               \n",
       "4       {'compound': 0.6908, 'neg': 0.0, 'neu': 0.908,...               \n",
       "...                                                   ...               \n",
       "633866  {'compound': 0.5574, 'neg': 0.0, 'neu': 0.839,...               \n",
       "633867  {'compound': 0.8316, 'neg': 0.0, 'neu': 0.755,...               \n",
       "633868  {'compound': 0.8779, 'neg': 0.0, 'neu': 0.59, ...               \n",
       "633869  {'compound': 0.5106, 'neg': 0.0, 'neu': 0.883,...               \n",
       "633870  {'compound': 0.9287, 'neg': 0.0, 'neu': 0.646,...               \n",
       "\n",
       "                                     sentence_composition  \\\n",
       "0       [55.00000000000001, 13.750000000000002, 17.5, ...   \n",
       "1       [60.18518518518518, 13.88888888888889, 18.5185...   \n",
       "2       [60.37735849056604, 9.433962264150944, 24.5283...   \n",
       "3       [53.84615384615385, 7.6923076923076925, 38.461...   \n",
       "4       [65.57377049180327, 13.114754098360656, 11.475...   \n",
       "...                                                   ...   \n",
       "633866  [57.14285714285714, 17.857142857142858, 14.285...   \n",
       "633867  [48.148148148148145, 11.11111111111111, 25.925...   \n",
       "633868  [52.38095238095239, 9.523809523809524, 38.0952...   \n",
       "633869  [60.0, 6.666666666666667, 33.33333333333333, 0...   \n",
       "633870  [56.666666666666664, 16.666666666666664, 26.66...   \n",
       "\n",
       "                                 publicremarks_embeddings  \\\n",
       "0       [-0.018459855, -0.023812085, -0.043892566, -0....   \n",
       "1       [-0.060909368, -0.044562507, -0.048587322, -0....   \n",
       "2       [0.051360507, -0.007422204, -0.054501485, -0.0...   \n",
       "3       [-0.020899976, 0.016856506, -0.011256389, -0.0...   \n",
       "4       [-0.047313046, 0.00859506, -0.04837404, -0.052...   \n",
       "...                                                   ...   \n",
       "633866  [-0.051895734, -0.034251053, 0.033765092, -0.0...   \n",
       "633867  [-0.014205737, -0.003559438, -0.062112767, -0....   \n",
       "633868  [-0.019684939, 0.010117671, -0.023263527, -0.0...   \n",
       "633869  [-0.021003596, -0.033517517, -0.030121898, -0....   \n",
       "633870  [-0.06345986, -0.008993911, -0.038106047, -0.0...   \n",
       "\n",
       "                           clean_publicremarks_embeddings  \\\n",
       "0       [-0.051987942, -0.054606345, -0.0580922, -0.03...   \n",
       "1       [-0.06049352, -0.05438737, -0.048537098, -0.05...   \n",
       "2       [-0.015618877, -0.03321094, -0.064131856, -0.0...   \n",
       "3       [-0.028272344, -0.005281781, -0.0073222406, -0...   \n",
       "4       [-0.055047132, -0.031499583, -0.055006824, -0....   \n",
       "...                                                   ...   \n",
       "633866  [-0.060446255, -0.039059404, -0.010817213, 0.0...   \n",
       "633867  [-0.026727155, -0.030834762, -0.06737272, -0.0...   \n",
       "633868  [-0.04207756, -0.019777237, -0.061898522, 0.02...   \n",
       "633869  [-0.010718957, -0.050030287, -0.042237516, -0....   \n",
       "633870  [-0.0641096, -0.056962736, -0.0384166, -0.0619...   \n",
       "\n",
       "          clean_publicremarks_additional_words_embeddings  \\\n",
       "0       [-0.05043851, -0.056709077, -0.055227116, -0.0...   \n",
       "1       [-0.059828583, -0.05020684, -0.046291806, -0.0...   \n",
       "2       [-0.011177328, -0.034213364, -0.06423391, -0.0...   \n",
       "3       [0.0036934454, 0.047616564, -0.0056924997, 0.0...   \n",
       "4       [-0.053909175, -0.025725972, -0.05363282, -0.0...   \n",
       "...                                                   ...   \n",
       "633866  [-0.05962046, -0.036440928, -0.007841245, 0.01...   \n",
       "633867  [-0.024440665, -0.016382039, -0.067579195, -0....   \n",
       "633868  [-0.03966484, -0.010800129, -0.06834481, 0.037...   \n",
       "633869  [0.0027086844, -0.048275027, -0.04004254, -0.0...   \n",
       "633870  [-0.05954439, -0.059571687, -0.03887053, -0.05...   \n",
       "\n",
       "                   clean_publicremarks_nopunct_embeddings  \\\n",
       "0       [-0.051987942, -0.054606345, -0.0580922, -0.03...   \n",
       "1       [-0.06049352, -0.05438737, -0.048537098, -0.05...   \n",
       "2       [-0.015618877, -0.03321094, -0.064131856, -0.0...   \n",
       "3       [-0.028272344, -0.005281781, -0.0073222406, -0...   \n",
       "4       [-0.055047132, -0.031499583, -0.055006824, -0....   \n",
       "...                                                   ...   \n",
       "633866  [-0.060446255, -0.039059404, -0.010817213, 0.0...   \n",
       "633867  [-0.026727155, -0.030834762, -0.06737272, -0.0...   \n",
       "633868  [-0.04207756, -0.019777237, -0.061898522, 0.02...   \n",
       "633869  [-0.010718957, -0.050030287, -0.042237516, -0....   \n",
       "633870  [-0.0641096, -0.056962736, -0.0384166, -0.0619...   \n",
       "\n",
       "                   clean_publicremarks_stemmed_embeddings  \\\n",
       "0       [-0.038664196, -0.05890688, -0.06525755, -0.02...   \n",
       "1       [-0.065291695, -0.06122866, -0.04930517, 0.006...   \n",
       "2       [-0.026406875, -0.061117634, -0.071621135, -0....   \n",
       "3       [-0.050069433, 0.007041185, -0.033259477, -0.0...   \n",
       "4       [-0.061100535, -0.05123385, -0.067388244, -0.0...   \n",
       "...                                                   ...   \n",
       "633866  [-0.054491606, -0.042947643, -0.054990385, 0.0...   \n",
       "633867  [0.0006334283, 0.008003559, -0.046898626, -0.0...   \n",
       "633868  [-0.016838605, -0.0041591953, -0.048585974, 0....   \n",
       "633869  [0.018240895, -0.050512295, -0.07150624, -0.04...   \n",
       "633870  [-0.05678726, -0.039550208, -0.022041079, -0.0...   \n",
       "\n",
       "                clean_publicremarks_lemmatized_embeddings  \n",
       "0       [-0.04986923, -0.05113033, -0.060150877, -0.03...  \n",
       "1       [-0.060174935, -0.05459462, -0.045611445, -0.0...  \n",
       "2       [-0.026331514, -0.048204094, -0.06567335, -0.0...  \n",
       "3       [-0.028272344, -0.005281781, -0.0073222406, -0...  \n",
       "4       [-0.054386344, -0.04275706, -0.052802, -0.0314...  \n",
       "...                                                   ...  \n",
       "633866  [-0.0584565, -0.023282561, -0.03466136, 0.0145...  \n",
       "633867  [-0.019545235, -0.03768261, -0.06952793, -0.04...  \n",
       "633868  [-0.03365848, -0.030594666, -0.061209537, 0.03...  \n",
       "633869  [-0.0015628912, -0.04374602, -0.05042092, -0.0...  \n",
       "633870  [-0.060876556, -0.061023917, -0.039990727, -0....  \n",
       "\n",
       "[633871 rows x 76 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['transaction_year'] = np.floor(np.array((df_sales['Transdate'].values/10000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['listingid', 'asgpropid', 'qtr', 'tax_year', 'cbsa_div', 'cbsa',\n",
       "       'state', 'Transdate', 'Transprice', 'bedrooms', 'total_value',\n",
       "       'cj_living_area', 'basement', 'has_pool', 'parking', 'is_poor',\n",
       "       'is_good', 'HAS_VIEW', 'has_golf', 'has_water', 'has_woods', 'has_hill',\n",
       "       'fips_code', 'census_tract', 'zip', 'effective_year_built', 'story',\n",
       "       'ListingPrice', 'publicremarks', 'avmValue', 'avmerror', 'rentsale',\n",
       "       'publicremarks_prepared', 'publicremarks_prepared_unicode',\n",
       "       'clean_publicremarks', 'clean_publicremarks_additional_words',\n",
       "       'clean_publicremarks_nopunct',\n",
       "       'clean_publicremarks_nopunct_additional_words',\n",
       "       'clean_publicremarks_stemmed',\n",
       "       'clean_publicremarks_stemmed_additional_words',\n",
       "       'clean_publicremarks_lemmatized',\n",
       "       'clean_publicremarks_lemmatized_additional_words',\n",
       "       'publicremarks_nltkpolarity', 'clean_publicremarks_nltkpolarity',\n",
       "       'clean_publicremarks_additional_words_nltkpolarity',\n",
       "       'clean_publicremarks_nopunct_nltkpolarity',\n",
       "       'clean_publicremarks_nopunct_additional_words_nltkpolarity',\n",
       "       'clean_publicremarks_stemmed_nltkpolarity',\n",
       "       'clean_publicremarks_stemmed_additional_words_nltkpolarity',\n",
       "       'clean_publicremarks_lemmatized_nltkpolarity',\n",
       "       'clean_publicremarks_lemmatized_additional_words_nltkpolarity',\n",
       "       'publicremarks_textblobpolarity',\n",
       "       'clean_publicremarks_textblobpolarity',\n",
       "       'clean_publicremarks_additional_words_textblobpolarity',\n",
       "       'clean_publicremarks_nopunct_textblobpolarity',\n",
       "       'clean_publicremarks_nopunct_additional_words_textblobpolarity',\n",
       "       'clean_publicremarks_stemmed_textblobpolarity',\n",
       "       'clean_publicremarks_stemmed_additional_words_textblobpolarity',\n",
       "       'clean_publicremarks_lemmatized_textblobpolarity',\n",
       "       'clean_publicremarks_lemmatized_additional_words_textblobpolarity',\n",
       "       'publicremarks_vaderpolarity', 'clean_publicremarks_vaderpolarity',\n",
       "       'clean_publicremarks_additional_words_vaderpolarity',\n",
       "       'clean_publicremarks_nopunct_vaderpolarity',\n",
       "       'clean_publicremarks_nopunct_additional_words_vaderpolarity',\n",
       "       'clean_publicremarks_stemmed_vaderpolarity',\n",
       "       'clean_publicremarks_stemmed_additional_words_vaderpolarity',\n",
       "       'clean_publicremarks_lemmatized_vaderpolarity',\n",
       "       'clean_publicremarks_lemmatized_additional_words_vaderpolarity',\n",
       "       'sentence_composition', 'publicremarks_embeddings',\n",
       "       'clean_publicremarks_embeddings',\n",
       "       'clean_publicremarks_additional_words_embeddings',\n",
       "       'clean_publicremarks_nopunct_embeddings',\n",
       "       'clean_publicremarks_stemmed_embeddings',\n",
       "       'clean_publicremarks_lemmatized_embeddings', 'transaction_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006.0\n",
      "2021.0\n"
     ]
    }
   ],
   "source": [
    "print(df_sales['transaction_year'].min())\n",
    "print(df_sales['transaction_year'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'bigrams_join',\n",
       " 'count_n_grams',\n",
       " 'defaultdict',\n",
       " 'df_get_n_grams_count',\n",
       " 'df_lambda_ngram',\n",
       " 'generate_n_grams',\n",
       " 'get_imp',\n",
       " 'get_n_grams_count',\n",
       " 'get_n_grams_probability',\n",
       " 'kg',\n",
       " 'ngrams',\n",
       " 'np',\n",
       " 'pd',\n",
       " 'text']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlp_pandas_functions import ngram_analysis\n",
    "reload(ngram_analysis)\n",
    "dir(ngram_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'bigrams_join',\n",
       " 'count_n_grams',\n",
       " 'defaultdict',\n",
       " 'df_get_n_grams_count',\n",
       " 'df_lambda_ngram',\n",
       " 'generate_n_grams',\n",
       " 'get_imp',\n",
       " 'get_n_grams_count',\n",
       " 'get_n_grams_probability',\n",
       " 'kg',\n",
       " 'ngrams',\n",
       " 'np',\n",
       " 'pd',\n",
       " 'text']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ngram_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_grams_probability(strtext, ngram, ngram_df):\n",
    "    df_ngram = ngram_analysis.get_n_grams_count(strtext,ngram)\n",
    "    df_ngram = df_ngram.rename({0: 'ngram', 1: 'count'}, axis='columns')\n",
    "    df_process = pd.merge(df_ngram, ngram_df, on=[\"ngram\"])\n",
    "    df_process['probability_mult'] = df_process['probability'] * df_process['count_x']\n",
    "    mean_prob =  (df_process['probability_mult'].sum() / df_process['count_x'].sum())\n",
    "    ngram_probs = list(df_process['probability'].quantile([.99, 0.95, 0.9, 0.75, 0.5, 0.25]))\n",
    "    ngram_probs.append(mean_prob)\n",
    "    return ngram_probs, df_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['publicremarks', 'clean_publicremarks', 'clean_publicremarks_additional_words',\n",
    "          'clean_publicremarks_nopunct', 'clean_publicremarks_nopunct_additional_words',\n",
    "           'clean_publicremarks_stemmed', 'clean_publicremarks_stemmed_additional_words', \n",
    "           'clean_publicremarks_lemmatized', 'clean_publicremarks_lemmatized_additional_words'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publicremarks\n",
      "Reading.. 29.528386999999995\n",
      "0 636149\n",
      "1 636149\n",
      "2 636149\n",
      "3 636149\n"
     ]
    }
   ],
   "source": [
    "columns = ['clean_publicremarks', 'clean_publicremarks_additional_words',\n",
    "          'clean_publicremarks_nopunct', 'clean_publicremarks_nopunct_additional_words',\n",
    "           'clean_publicremarks_stemmed', 'clean_publicremarks_stemmed_additional_words', \n",
    "           'clean_publicremarks_lemmatized', 'clean_publicremarks_lemmatized_additional_words'\n",
    "           ]\n",
    "\n",
    "suffix_1 = ['_ngram_probs_1_99', '_ngram_probs_1_95', '_ngram_probs_1_90', \n",
    "            '_ngram_probs_1_75', '_ngram_probs_1_50', '_ngram_probs_1_25', '_ngram_probs_1_MN']\n",
    "suffix_2 = ['_ngram_probs_2_99', '_ngram_probs_2_95', '_ngram_probs_2_90', \n",
    "            '_ngram_probs_2_75', '_ngram_probs_2_50', '_ngram_probs_2_25', '_ngram_probs_2_MN']\n",
    "suffix_3 = ['_ngram_probs_3_99', '_ngram_probs_3_95', '_ngram_probs_3_90', \n",
    "            '_ngram_probs_3_75', '_ngram_probs_3_50', '_ngram_probs_3_25', '_ngram_probs_3_MN']\n",
    "suffix_4 = ['_ngram_probs_4_99', '_ngram_probs_4_95', '_ngram_probs_4_90', \n",
    "            '_ngram_probs_4_75', '_ngram_probs_4_50', '_ngram_probs_4_25', '_ngram_probs_4_MN']\n",
    "\n",
    "\n",
    "for column in columns:\n",
    "    print(column)\n",
    "    \n",
    "    tic = time.clock()\n",
    "    unigram_df = pd.read_feather('ngrams/' + file + '_withsentiment_' + column + '_unigram.fea')\n",
    "    bigram_df = pd.read_feather('ngrams/' + file + '_withsentiment_' + column + '_bigram.fea')\n",
    "    trigram_df = pd.read_feather('ngrams/' + file + '_withsentiment_' + column + '_trigram.fea')\n",
    "    fourgram_df = pd.read_feather('ngrams/' + file + '_withsentiment_' + column + '_fourgram.fea')\n",
    "    \n",
    "    toc_r = time.clock()\n",
    "    print('Reading..',toc_r - tic)\n",
    "    \n",
    "    ngram_probs_array_uni = np.zeros([len(df_sales), 7])  \n",
    "    ngram_probs_array_bi = np.zeros([len(df_sales), 7])\n",
    "    ngram_probs_array_tri = np.zeros([len(df_sales), 7])\n",
    "    ngram_probs_array_four = np.zeros([len(df_sales), 7])\n",
    "    \n",
    "    column_names_1 = []\n",
    "    for cn in suffix_1:\n",
    "        column_names_1.append(column + cn)\n",
    "        \n",
    "    column_names_2 = []\n",
    "    for cn in suffix_2:\n",
    "        column_names_2.append(column + cn)\n",
    "        \n",
    "    column_names_3 = []\n",
    "    for cn in suffix_3:\n",
    "        column_names_3.append(column + cn)\n",
    "        \n",
    "    column_names_4 = []\n",
    "    for cn in suffix_4:\n",
    "        column_names_4.append(column + cn)\n",
    "        \n",
    "    for house in df_sales.index:\n",
    "        print(house, len(df_sales.index))\n",
    "                   \n",
    "        tic = time.clock()\n",
    "        ngram_probs, df_process = get_n_grams_probability(df_sales[column][house], \n",
    "                                                          1, unigram_df)\n",
    "        ngram_probs_array_uni[house, :] = ngram_probs\n",
    "\n",
    "        tic = time.clock()\n",
    "        ngram_probs, df_process = get_n_grams_probability(df_sales[column][house], \n",
    "                                                          2, bigram_df)\n",
    "        ngram_probs_array_bi[house, :] = ngram_probs\n",
    "\n",
    "        tic = time.clock()\n",
    "        ngram_probs, df_process = get_n_grams_probability(df_sales[column][house], \n",
    "                                                          3, trigram_df)\n",
    "        ngram_probs_array_tri[house, :] = ngram_probs\n",
    "\n",
    "        tic = time.clock()\n",
    "        ngram_probs, df_process = get_n_grams_probability(df_sales[column][house], \n",
    "                                                          4, fourgram_df)\n",
    "        ngram_probs_array_four[house, :] = ngram_probs \n",
    "\n",
    "    for cid, colum_id in enumerate(column_names_3):\n",
    "        df_sales[colum_id] = ngram_probs_array_tri[:, cid].tolist() \n",
    "        \n",
    "    for cid, colum_id in enumerate(column_names_1):\n",
    "        df_sales[colum_id] = ngram_probs_array_uni[:, cid].tolist()   \n",
    "\n",
    "    for cid, colum_id in enumerate(column_names_2):\n",
    "        df_sales[colum_id] = ngram_probs_array_bi[:, cid].tolist() \n",
    "\n",
    "    for cid, colum_id in enumerate(column_names_4):\n",
    "        df_sales[colum_id] = ngram_probs_array_four[:, cid].tolist() \n",
    "        \n",
    "    toc = time.clock()\n",
    "    print(toc - tic)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.to_feather(file + '_withsentiment_sentencecomposition_' + 'ngram_probability' + '.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales[column][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column = 'clean_publicremarks_nopunct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigram_df = pd.read_feather('ngrams/' + file + '_withsentiment_' + column + '_unigram.fea')\n",
    "#bigram_df = pd.read_feather('ngrams/' + file + '_withsentiment_' + column + '_bigram.fea')\n",
    "#trigram_df = pd.read_feather('ngrams/' + file + '_withsentiment_' + column + '_trigram.fea')\n",
    "#fourgram_df = pd.read_feather('ngrams/' + file + '_withsentiment_' + column + '_fourgram.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigram_df[unigram_df['ngram'] == 'house']['probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sales['publicremarks'].values[house])\n",
    "print(df_sales['ListingPrice'].values[house])\n",
    "print(df_sales['avmValue'].values[house])\n",
    "print(df_sales['Transprice'].values[house])\n",
    "print(df_sales['avmerror'].values[house])\n",
    "print((df_sales['Transprice'].values[house]-(df_sales['avmValue'].values[house]))/df_sales['Transprice'].values[house])\n",
    "print((df_sales['Transprice'].values[house]-(df_sales['ListingPrice'].values[house]))/df_sales['Transprice'].values[house])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['clean_publicremarks_nopunct'].values[house]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process = get_n_grams_probability(df_sales['clean_publicremarks_nopunct'].values[house], 2, bigram_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_analysis.get_n_grams_count(df_sales['clean_publicremarks_nopunct'].values[house],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process.probability.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process.probability.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_df = unigram_df.rename({0: 'ngram', 1: 'count'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
