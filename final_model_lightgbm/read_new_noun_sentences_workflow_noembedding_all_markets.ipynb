{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import moment\n",
    "from scipy.stats import describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/cdsw/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import moment\n",
    "from scipy.stats import describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_stats_error(datalist):\n",
    "    \n",
    "    if len(datalist)>1:\n",
    "        result_describe = list(describe(datalist)[2:])\n",
    "        result_percentile = result_describe + list(np.percentile(datalist,[10,25,50,75,90]))\n",
    "        array = np.array(datalist)\n",
    "        result_percentile = result_percentile+[len(array),len(array[np.where(array>0)[0]])/len(array)*100,\n",
    "                                               len(array[np.where(array<0)[0]])/len(array)*100]\n",
    "    else:\n",
    "        result_percentile = []\n",
    "\n",
    "    return result_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(df, lst_cols, fill_value=''):\n",
    "    # make sure `lst_cols` is a list\n",
    "    if lst_cols and not isinstance(lst_cols, list):\n",
    "        lst_cols = [lst_cols]\n",
    "    # all columns except `lst_cols`\n",
    "    idx_cols = df.columns.difference(lst_cols)\n",
    "\n",
    "    # calculate lengths of lists\n",
    "    lens = df[lst_cols[0]].str.len()\n",
    "\n",
    "    if (lens > 0).all():\n",
    "        # ALL lists in cells aren't empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .loc[:, df.columns]\n",
    "    else:\n",
    "        # at least one list in cells is empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .append(df.loc[lens==0, idx_cols]).fillna(fill_value) \\\n",
    "          .loc[:, df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-16 19:10:51,583 loading file /home/cdsw/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n",
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'bigrams_join',\n",
       " 'count_n_grams',\n",
       " 'defaultdict',\n",
       " 'df_get_n_grams_count',\n",
       " 'df_lambda_ngram',\n",
       " 'generate_n_grams',\n",
       " 'get_imp',\n",
       " 'get_n_grams_count',\n",
       " 'get_n_grams_probability',\n",
       " 'kg',\n",
       " 'ngrams',\n",
       " 'np',\n",
       " 'pd',\n",
       " 'text']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "from nlp_pandas_functions import ngram_analysis\n",
    "from nlp_pandas_functions import noun_sentences\n",
    "\n",
    "reload(ngram_analysis)\n",
    "reload(noun_sentences)\n",
    "dir(ngram_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'clean_publicremarks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'nlp_pandas_functions.noun_sentences' from '/home/cdsw/final_model_lightgbm/nlp_pandas_functions/noun_sentences.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from nlp_pandas_functions import ngram_analysis\n",
    "from nlp_pandas_functions import noun_sentences\n",
    "\n",
    "#reload(ngram_analysis)\n",
    "reload(noun_sentences)\n",
    "#dir(ngram_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "filtered_files = glob.glob(\"new_avm_df_state_*_noun_sentences.fea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_avm_df_state_TX_noun_sentences.fea',\n",
       " 'new_avm_df_state_KS_noun_sentences.fea',\n",
       " 'new_avm_df_state_AZ_noun_sentences.fea',\n",
       " 'new_avm_df_state_TN_noun_sentences.fea',\n",
       " 'new_avm_df_state_FL_noun_sentences.fea',\n",
       " 'new_avm_df_state_GA_noun_sentences.fea',\n",
       " 'new_avm_df_state_OK_noun_sentences.fea',\n",
       " 'new_avm_df_state_UT_noun_sentences.fea',\n",
       " 'new_avm_df_state_ME_noun_sentences.fea',\n",
       " 'new_avm_df_state_CA_noun_sentences.fea',\n",
       " 'new_avm_df_state_MS_noun_sentences.fea',\n",
       " 'new_avm_df_state_WA_noun_sentences.fea',\n",
       " 'new_avm_df_state_OH_noun_sentences.fea',\n",
       " 'new_avm_df_state_MA_noun_sentences.fea',\n",
       " 'new_avm_df_state_AL_noun_sentences.fea',\n",
       " 'new_avm_df_state_NC_noun_sentences.fea',\n",
       " 'new_avm_df_state_CO_noun_sentences.fea',\n",
       " 'new_avm_df_state_MO_noun_sentences.fea',\n",
       " 'new_avm_df_state_KY_noun_sentences.fea',\n",
       " 'new_avm_df_state_NE_noun_sentences.fea',\n",
       " 'new_avm_df_state_NY_noun_sentences.fea',\n",
       " 'new_avm_df_state_VA_noun_sentences.fea',\n",
       " 'new_avm_df_state_MD_noun_sentences.fea',\n",
       " 'new_avm_df_state_HI_noun_sentences.fea',\n",
       " 'new_avm_df_state_WV_noun_sentences.fea',\n",
       " 'new_avm_df_state_MN_noun_sentences.fea',\n",
       " 'new_avm_df_state_AK_noun_sentences.fea',\n",
       " 'new_avm_df_state_IN_noun_sentences.fea',\n",
       " 'new_avm_df_state_PA_noun_sentences.fea',\n",
       " 'new_avm_df_state_SC_noun_sentences.fea',\n",
       " 'new_avm_df_state_LA_noun_sentences.fea',\n",
       " 'new_avm_df_state_NJ_noun_sentences.fea',\n",
       " 'new_avm_df_state_RI_noun_sentences.fea',\n",
       " 'new_avm_df_state_WY_noun_sentences.fea']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_avm_df_state_AL_noun_sentences.fea\n",
      "new_avm_df_state_NC_noun_sentences.fea\n",
      "new_avm_df_state_CO_noun_sentences.fea\n",
      "new_avm_df_state_MO_noun_sentences.fea\n",
      "new_avm_df_state_KY_noun_sentences.fea\n",
      "new_avm_df_state_NE_noun_sentences.fea\n",
      "new_avm_df_state_NY_noun_sentences.fea\n",
      "new_avm_df_state_VA_noun_sentences.fea\n",
      "new_avm_df_state_MD_noun_sentences.fea\n",
      "new_avm_df_state_HI_noun_sentences.fea\n",
      "new_avm_df_state_WV_noun_sentences.fea\n",
      "new_avm_df_state_MN_noun_sentences.fea\n",
      "new_avm_df_state_AK_noun_sentences.fea\n",
      "new_avm_df_state_IN_noun_sentences.fea\n",
      "new_avm_df_state_PA_noun_sentences.fea\n",
      "new_avm_df_state_SC_noun_sentences.fea\n",
      "new_avm_df_state_LA_noun_sentences.fea\n",
      "new_avm_df_state_NJ_noun_sentences.fea\n",
      "new_avm_df_state_RI_noun_sentences.fea\n",
      "new_avm_df_state_WY_noun_sentences.fea\n"
     ]
    }
   ],
   "source": [
    "for file in filtered_files[14:]:\n",
    "    \n",
    "    print(file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filtered_files[34:]:\n",
    "    \n",
    "    print(file)    \n",
    "    \n",
    "    noun_sentence_df_T_ri_filtered = pd.read_feather(file)\n",
    "    print(len(noun_sentence_df_T_ri_filtered))\n",
    "    \n",
    "    noun_sentence_df_T_ri_filtered = noun_sentence_df_T_ri_filtered[noun_sentence_df_T_ri_filtered['count'] > 200]\n",
    "    \n",
    "    file_join = file.split('.')[0] + '_filtered_noun_sentences_errors_CJ.fea'\n",
    "    noun_sentence_df_T_ri_filtered.to_csv(file_join)    \n",
    "    \n",
    "    noun_sentence_df_T_ri_filtered_thu = noun_sentence_df_T_ri_filtered.loc[:,['noun_sentence','Listingid_List']]\n",
    "    noun_sentence_df_T_ri_filtered_thu_list = explode(noun_sentence_df_T_ri_filtered_thu,\n",
    "                                           lst_cols=['Listingid_List'])\n",
    "    noun_sentence_df_T_ri_filtered_thu_list = noun_sentence_df_T_ri_filtered_thu_list.sort_values('Listingid_List')\n",
    "    noun_sentence_df_T_ri_filtered_thu_list = noun_sentence_df_T_ri_filtered_thu_list.rename(columns={'Listingid_List':'listingid'})\n",
    "    \n",
    "    noun_sentence_df_T_ri_filtered_thu_list = noun_sentence_df_T_ri_filtered_thu_list.drop_duplicates()\n",
    "    \n",
    "    file_join = file.split('.')[0] +'_noun_sentences_by_listingid_CJ.fea'\n",
    "    noun_sentence_df_T_ri_filtered_thu_list.to_csv(file_join)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filtered_files[29:]:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun_sentence</th>\n",
       "      <th>count</th>\n",
       "      <th>AVM_Error</th>\n",
       "      <th>AVM_Error_List</th>\n",
       "      <th>Listing_Error</th>\n",
       "      <th>Listing_Error_List</th>\n",
       "      <th>Listingid_List</th>\n",
       "      <th>AVM_Error_Average</th>\n",
       "      <th>Listing_Error_Average</th>\n",
       "      <th>AVM_Error_Indicators</th>\n",
       "      <th>Listing_Error_Indicators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [noun_sentence, count, AVM_Error, AVM_Error_List, Listing_Error, Listing_Error_List, Listingid_List, AVM_Error_Average, Listing_Error_Average, AVM_Error_Indicators, Listing_Error_Indicators]\n",
       "Index: []"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_sentence_df_T_ri_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_sentence_df_T_ri_filtered_thu = noun_sentence_df_T_ri_filtered.loc[:,['noun_sentence','Listingid_List']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun_sentence</th>\n",
       "      <th>Listingid_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162046</th>\n",
       "      <td>new bathrooms</td>\n",
       "      <td>[226771172, 226894344, 226798752, 226705586, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191942</th>\n",
       "      <td>measurements approximate</td>\n",
       "      <td>[226789511, 226972662, 227216981, 227220287, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204925</th>\n",
       "      <td>top bottom</td>\n",
       "      <td>[226874336, 227335468, 227067931, 227204798, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207082</th>\n",
       "      <td>quartz countertops</td>\n",
       "      <td>[227126688, 227163953, 227060322, 227137424, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225617</th>\n",
       "      <td>new cabinets</td>\n",
       "      <td>[226894344, 226755849, 226967145, 226807551, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808440</th>\n",
       "      <td>great potential</td>\n",
       "      <td>[227171512, 227359007, 228392861, 228820100, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809053</th>\n",
       "      <td>major interstates</td>\n",
       "      <td>[227154427, 226931146, 227598976, 229566962, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812573</th>\n",
       "      <td>great investment property</td>\n",
       "      <td>[226801678, 226766720, 227620770, 227835706, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822110</th>\n",
       "      <td>needs tlc</td>\n",
       "      <td>[10193559, 228298342, 231697221, 233081549, 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825132</th>\n",
       "      <td>right redemption</td>\n",
       "      <td>[226766720, 43307986, 175819212, 187496529, 18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1230 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    noun_sentence  \\\n",
       "162046              new bathrooms   \n",
       "191942   measurements approximate   \n",
       "204925                 top bottom   \n",
       "207082         quartz countertops   \n",
       "225617               new cabinets   \n",
       "...                           ...   \n",
       "808440            great potential   \n",
       "809053          major interstates   \n",
       "812573  great investment property   \n",
       "822110                  needs tlc   \n",
       "825132           right redemption   \n",
       "\n",
       "                                           Listingid_List  \n",
       "162046  [226771172, 226894344, 226798752, 226705586, 2...  \n",
       "191942  [226789511, 226972662, 227216981, 227220287, 2...  \n",
       "204925  [226874336, 227335468, 227067931, 227204798, 2...  \n",
       "207082  [227126688, 227163953, 227060322, 227137424, 2...  \n",
       "225617  [226894344, 226755849, 226967145, 226807551, 2...  \n",
       "...                                                   ...  \n",
       "808440  [227171512, 227359007, 228392861, 228820100, 2...  \n",
       "809053  [227154427, 226931146, 227598976, 229566962, 2...  \n",
       "812573  [226801678, 226766720, 227620770, 227835706, 2...  \n",
       "822110  [10193559, 228298342, 231697221, 233081549, 23...  \n",
       "825132  [226766720, 43307986, 175819212, 187496529, 18...  \n",
       "\n",
       "[1230 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_sentence_df_T_ri_filtered_thu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_sentence_df_T_ri_filtered_thu_list = explode(noun_sentence_df_T_ri_filtered_thu,\n",
    "                                           lst_cols=['Listingid_List'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun_sentence</th>\n",
       "      <th>Listingid_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new bathrooms</td>\n",
       "      <td>226771172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new bathrooms</td>\n",
       "      <td>226894344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new bathrooms</td>\n",
       "      <td>226798752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new bathrooms</td>\n",
       "      <td>226705586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new bathrooms</td>\n",
       "      <td>226773117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128967</th>\n",
       "      <td>right redemption</td>\n",
       "      <td>10173537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128968</th>\n",
       "      <td>right redemption</td>\n",
       "      <td>83277261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128969</th>\n",
       "      <td>right redemption</td>\n",
       "      <td>10176800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128970</th>\n",
       "      <td>right redemption</td>\n",
       "      <td>10303984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128971</th>\n",
       "      <td>right redemption</td>\n",
       "      <td>10171719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            noun_sentence  Listingid_List\n",
       "0           new bathrooms       226771172\n",
       "1           new bathrooms       226894344\n",
       "2           new bathrooms       226798752\n",
       "3           new bathrooms       226705586\n",
       "4           new bathrooms       226773117\n",
       "...                   ...             ...\n",
       "1128967  right redemption        10173537\n",
       "1128968  right redemption        83277261\n",
       "1128969  right redemption        10176800\n",
       "1128970  right redemption        10303984\n",
       "1128971  right redemption        10171719\n",
       "\n",
       "[1128972 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_sentence_df_T_ri_filtered_thu_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
