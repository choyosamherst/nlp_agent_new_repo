{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-31 20:14:47,389 loading file /home/cdsw/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    }
   ],
   "source": [
    "import nlp_pandas_functions as npf\n",
    "#dir(npf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install pyarrow\n",
    "#pip3 install spacy\n",
    "#pip3 install wordcloud\n",
    "#pip3 install nltk\n",
    "#pip3 install sklearn\n",
    "#pip3 install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_state = 'GA'\n",
    "file = 'agent_comments_sales_'+str_state\n",
    "#file = 'agent_comments_testdf'\n",
    "#READ THE SALES DATA - STATE\n",
    "df_sales = pd.read_feather(file + '_sentencecomposition.fea')\n",
    "#df_sales = pd.read_feather(file+'_processed.fea')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_save = df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = df_sales_save#.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>listingid</th>\n",
       "      <th>asgpropid</th>\n",
       "      <th>qtr</th>\n",
       "      <th>tax_year</th>\n",
       "      <th>cbsa_div</th>\n",
       "      <th>cbsa</th>\n",
       "      <th>state</th>\n",
       "      <th>Transdate</th>\n",
       "      <th>Transprice</th>\n",
       "      <th>...</th>\n",
       "      <th>publicremarks_vaderpolarity</th>\n",
       "      <th>clean_publicremarks_vaderpolarity</th>\n",
       "      <th>clean_publicremarks_additional_words_vaderpolarity</th>\n",
       "      <th>clean_publicremarks_nopunct_vaderpolarity</th>\n",
       "      <th>clean_publicremarks_nopunct_additional_words_vaderpolarity</th>\n",
       "      <th>clean_publicremarks_stemmed_vaderpolarity</th>\n",
       "      <th>clean_publicremarks_stemmed_additional_words_vaderpolarity</th>\n",
       "      <th>clean_publicremarks_lemmatized_vaderpolarity</th>\n",
       "      <th>clean_publicremarks_lemmatized_additional_words_vaderpolarity</th>\n",
       "      <th>sentence_composition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>226661582</td>\n",
       "      <td>27649366.0</td>\n",
       "      <td>202008</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>23580</td>\n",
       "      <td>23580</td>\n",
       "      <td>GA</td>\n",
       "      <td>20200811</td>\n",
       "      <td>359000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.9627, 'neg': 0.0, 'neu': 0.86, ...</td>\n",
       "      <td>{'compound': 0.9627, 'neg': 0.0, 'neu': 0.781,...</td>\n",
       "      <td>{'compound': 0.9401, 'neg': 0.0, 'neu': 0.803,...</td>\n",
       "      <td>{'compound': 0.9578, 'neg': 0.0, 'neu': 0.786,...</td>\n",
       "      <td>{'compound': 0.93, 'neg': 0.0, 'neu': 0.81, 'p...</td>\n",
       "      <td>{'compound': 0.6486, 'neg': 0.0, 'neu': 0.936,...</td>\n",
       "      <td>{'compound': 0.4939, 'neg': 0.0, 'neu': 0.954,...</td>\n",
       "      <td>{'compound': 0.9578, 'neg': 0.0, 'neu': 0.786,...</td>\n",
       "      <td>{'compound': 0.93, 'neg': 0.0, 'neu': 0.81, 'p...</td>\n",
       "      <td>[63.74999999999999, 20.0, 21.25, 1.25, 1.25, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "      <td>226786904</td>\n",
       "      <td>27628370.0</td>\n",
       "      <td>202008</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>29300</td>\n",
       "      <td>29300</td>\n",
       "      <td>GA</td>\n",
       "      <td>20200925</td>\n",
       "      <td>265000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.9939, 'neg': 0.015, 'neu': 0.70...</td>\n",
       "      <td>{'compound': 0.9898, 'neg': 0.013, 'neu': 0.70...</td>\n",
       "      <td>{'compound': 0.9876, 'neg': 0.015, 'neu': 0.70...</td>\n",
       "      <td>{'compound': 0.9889, 'neg': 0.014, 'neu': 0.69...</td>\n",
       "      <td>{'compound': 0.9864, 'neg': 0.016, 'neu': 0.7,...</td>\n",
       "      <td>{'compound': 0.9732, 'neg': 0.0, 'neu': 0.801,...</td>\n",
       "      <td>{'compound': 0.9686, 'neg': 0.0, 'neu': 0.799,...</td>\n",
       "      <td>{'compound': 0.9875, 'neg': 0.014, 'neu': 0.70...</td>\n",
       "      <td>{'compound': 0.9844, 'neg': 0.016, 'neu': 0.70...</td>\n",
       "      <td>[47.22222222222222, 14.814814814814813, 15.740...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>232</td>\n",
       "      <td>226142320</td>\n",
       "      <td>27963359.0</td>\n",
       "      <td>202005</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>27600</td>\n",
       "      <td>27600</td>\n",
       "      <td>GA</td>\n",
       "      <td>20200624</td>\n",
       "      <td>239900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.8528, 'neg': 0.0, 'neu': 0.893,...</td>\n",
       "      <td>{'compound': 0.8221, 'neg': 0.0, 'neu': 0.853,...</td>\n",
       "      <td>{'compound': 0.8221, 'neg': 0.0, 'neu': 0.851,...</td>\n",
       "      <td>{'compound': 0.8074, 'neg': 0.0, 'neu': 0.858,...</td>\n",
       "      <td>{'compound': 0.8074, 'neg': 0.0, 'neu': 0.855,...</td>\n",
       "      <td>{'compound': 0.3182, 'neg': 0.0, 'neu': 0.958,...</td>\n",
       "      <td>{'compound': 0.3182, 'neg': 0.0, 'neu': 0.957,...</td>\n",
       "      <td>{'compound': 0.8074, 'neg': 0.0, 'neu': 0.858,...</td>\n",
       "      <td>{'compound': 0.8074, 'neg': 0.0, 'neu': 0.855,...</td>\n",
       "      <td>[96.22641509433963, 30.18867924528302, 32.0754...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>308</td>\n",
       "      <td>226738459</td>\n",
       "      <td>27516267.0</td>\n",
       "      <td>202008</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>29300</td>\n",
       "      <td>29300</td>\n",
       "      <td>GA</td>\n",
       "      <td>20200713</td>\n",
       "      <td>130900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...</td>\n",
       "      <td>{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...</td>\n",
       "      <td>{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...</td>\n",
       "      <td>{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...</td>\n",
       "      <td>{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...</td>\n",
       "      <td>{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...</td>\n",
       "      <td>{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...</td>\n",
       "      <td>{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...</td>\n",
       "      <td>{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...</td>\n",
       "      <td>[392.30769230769226, 123.07692307692308, 130.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>467</td>\n",
       "      <td>226850183</td>\n",
       "      <td>27791872.0</td>\n",
       "      <td>202008</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>23580</td>\n",
       "      <td>23580</td>\n",
       "      <td>GA</td>\n",
       "      <td>20200702</td>\n",
       "      <td>406000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.8829, 'neg': 0.0, 'neu': 0.877,...</td>\n",
       "      <td>{'compound': 0.8829, 'neg': 0.0, 'neu': 0.849,...</td>\n",
       "      <td>{'compound': 0.8309, 'neg': 0.0, 'neu': 0.878,...</td>\n",
       "      <td>{'compound': 0.8658, 'neg': 0.0, 'neu': 0.857,...</td>\n",
       "      <td>{'compound': 0.802, 'neg': 0.0, 'neu': 0.886, ...</td>\n",
       "      <td>{'compound': 0.5106, 'neg': 0.0, 'neu': 0.932,...</td>\n",
       "      <td>{'compound': 0.2023, 'neg': 0.0, 'neu': 0.969,...</td>\n",
       "      <td>{'compound': 0.802, 'neg': 0.0, 'neu': 0.876, ...</td>\n",
       "      <td>{'compound': 0.6908, 'neg': 0.0, 'neu': 0.908,...</td>\n",
       "      <td>[83.60655737704919, 26.229508196721312, 27.868...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>636144</td>\n",
       "      <td>6908610</td>\n",
       "      <td>77898274</td>\n",
       "      <td>106321613.0</td>\n",
       "      <td>200708</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>27600</td>\n",
       "      <td>27600</td>\n",
       "      <td>GA</td>\n",
       "      <td>20070719</td>\n",
       "      <td>163900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.7684, 'neg': 0.0, 'neu': 0.832,...</td>\n",
       "      <td>{'compound': 0.6351, 'neg': 0.0, 'neu': 0.834,...</td>\n",
       "      <td>{'compound': 0.6351, 'neg': 0.0, 'neu': 0.822,...</td>\n",
       "      <td>{'compound': 0.5574, 'neg': 0.0, 'neu': 0.85, ...</td>\n",
       "      <td>{'compound': 0.5574, 'neg': 0.0, 'neu': 0.839,...</td>\n",
       "      <td>{'compound': 0.5574, 'neg': 0.0, 'neu': 0.85, ...</td>\n",
       "      <td>{'compound': 0.5574, 'neg': 0.0, 'neu': 0.839,...</td>\n",
       "      <td>{'compound': 0.5574, 'neg': 0.0, 'neu': 0.85, ...</td>\n",
       "      <td>{'compound': 0.5574, 'neg': 0.0, 'neu': 0.839,...</td>\n",
       "      <td>[182.14285714285714, 57.14285714285714, 60.714...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>636145</td>\n",
       "      <td>6912211</td>\n",
       "      <td>77863520</td>\n",
       "      <td>131534737.0</td>\n",
       "      <td>200705</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>23580</td>\n",
       "      <td>23580</td>\n",
       "      <td>GA</td>\n",
       "      <td>20070430</td>\n",
       "      <td>292300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.8741, 'neg': 0.0, 'neu': 0.764,...</td>\n",
       "      <td>{'compound': 0.8741, 'neg': 0.0, 'neu': 0.736,...</td>\n",
       "      <td>{'compound': 0.8741, 'neg': 0.0, 'neu': 0.728,...</td>\n",
       "      <td>{'compound': 0.8316, 'neg': 0.0, 'neu': 0.762,...</td>\n",
       "      <td>{'compound': 0.8316, 'neg': 0.0, 'neu': 0.755,...</td>\n",
       "      <td>{'compound': 0.6249, 'neg': 0.0, 'neu': 0.864,...</td>\n",
       "      <td>{'compound': 0.6249, 'neg': 0.0, 'neu': 0.859,...</td>\n",
       "      <td>{'compound': 0.8316, 'neg': 0.0, 'neu': 0.762,...</td>\n",
       "      <td>{'compound': 0.8316, 'neg': 0.0, 'neu': 0.755,...</td>\n",
       "      <td>[188.88888888888889, 59.25925925925925, 62.962...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>636146</td>\n",
       "      <td>6912289</td>\n",
       "      <td>77900119</td>\n",
       "      <td>131589092.0</td>\n",
       "      <td>200708</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>23580</td>\n",
       "      <td>23580</td>\n",
       "      <td>GA</td>\n",
       "      <td>20070831</td>\n",
       "      <td>181000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.8779, 'neg': 0.0, 'neu': 0.684,...</td>\n",
       "      <td>{'compound': 0.8779, 'neg': 0.0, 'neu': 0.605,...</td>\n",
       "      <td>{'compound': 0.8779, 'neg': 0.0, 'neu': 0.59, ...</td>\n",
       "      <td>{'compound': 0.8779, 'neg': 0.0, 'neu': 0.605,...</td>\n",
       "      <td>{'compound': 0.8779, 'neg': 0.0, 'neu': 0.59, ...</td>\n",
       "      <td>{'compound': 0.7506, 'neg': 0.0, 'neu': 0.748,...</td>\n",
       "      <td>{'compound': 0.7506, 'neg': 0.0, 'neu': 0.738,...</td>\n",
       "      <td>{'compound': 0.8779, 'neg': 0.0, 'neu': 0.605,...</td>\n",
       "      <td>{'compound': 0.8779, 'neg': 0.0, 'neu': 0.59, ...</td>\n",
       "      <td>[242.85714285714283, 76.19047619047619, 80.952...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>636147</td>\n",
       "      <td>6912290</td>\n",
       "      <td>77861631</td>\n",
       "      <td>131589103.0</td>\n",
       "      <td>200702</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>23580</td>\n",
       "      <td>23580</td>\n",
       "      <td>GA</td>\n",
       "      <td>20070214</td>\n",
       "      <td>179800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.6341, 'neg': 0.0, 'neu': 0.881,...</td>\n",
       "      <td>{'compound': 0.6341, 'neg': 0.0, 'neu': 0.862,...</td>\n",
       "      <td>{'compound': 0.6341, 'neg': 0.0, 'neu': 0.857,...</td>\n",
       "      <td>{'compound': 0.5106, 'neg': 0.0, 'neu': 0.887,...</td>\n",
       "      <td>{'compound': 0.5106, 'neg': 0.0, 'neu': 0.883,...</td>\n",
       "      <td>{'compound': 0.3612, 'neg': 0.0, 'neu': 0.912,...</td>\n",
       "      <td>{'compound': 0.3612, 'neg': 0.0, 'neu': 0.909,...</td>\n",
       "      <td>{'compound': 0.5106, 'neg': 0.0, 'neu': 0.887,...</td>\n",
       "      <td>{'compound': 0.5106, 'neg': 0.0, 'neu': 0.883,...</td>\n",
       "      <td>[170.0, 53.333333333333336, 56.666666666666664...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>636148</td>\n",
       "      <td>6912291</td>\n",
       "      <td>77883696</td>\n",
       "      <td>131589105.0</td>\n",
       "      <td>200705</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>23580</td>\n",
       "      <td>23580</td>\n",
       "      <td>GA</td>\n",
       "      <td>20070420</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'compound': 0.9613, 'neg': 0.0, 'neu': 0.673,...</td>\n",
       "      <td>{'compound': 0.939, 'neg': 0.0, 'neu': 0.658, ...</td>\n",
       "      <td>{'compound': 0.939, 'neg': 0.0, 'neu': 0.649, ...</td>\n",
       "      <td>{'compound': 0.9287, 'neg': 0.0, 'neu': 0.655,...</td>\n",
       "      <td>{'compound': 0.9287, 'neg': 0.0, 'neu': 0.646,...</td>\n",
       "      <td>{'compound': 0.8481, 'neg': 0.0, 'neu': 0.773,...</td>\n",
       "      <td>{'compound': 0.8481, 'neg': 0.0, 'neu': 0.767,...</td>\n",
       "      <td>{'compound': 0.9287, 'neg': 0.0, 'neu': 0.655,...</td>\n",
       "      <td>{'compound': 0.9287, 'neg': 0.0, 'neu': 0.646,...</td>\n",
       "      <td>[170.0, 53.333333333333336, 56.666666666666664...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636149 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          index  listingid    asgpropid     qtr  tax_year cbsa_div   cbsa  \\\n",
       "0           128  226661582   27649366.0  202008    2020.0    23580  23580   \n",
       "1           190  226786904   27628370.0  202008    2020.0    29300  29300   \n",
       "2           232  226142320   27963359.0  202005    2020.0    27600  27600   \n",
       "3           308  226738459   27516267.0  202008    2020.0    29300  29300   \n",
       "4           467  226850183   27791872.0  202008    2020.0    23580  23580   \n",
       "...         ...        ...          ...     ...       ...      ...    ...   \n",
       "636144  6908610   77898274  106321613.0  200708    2013.0    27600  27600   \n",
       "636145  6912211   77863520  131534737.0  200705    2013.0    23580  23580   \n",
       "636146  6912289   77900119  131589092.0  200708    2013.0    23580  23580   \n",
       "636147  6912290   77861631  131589103.0  200702    2013.0    23580  23580   \n",
       "636148  6912291   77883696  131589105.0  200705    2013.0    23580  23580   \n",
       "\n",
       "       state  Transdate  Transprice  ...  \\\n",
       "0         GA   20200811    359000.0  ...   \n",
       "1         GA   20200925    265000.0  ...   \n",
       "2         GA   20200624    239900.0  ...   \n",
       "3         GA   20200713    130900.0  ...   \n",
       "4         GA   20200702    406000.0  ...   \n",
       "...      ...        ...         ...  ...   \n",
       "636144    GA   20070719    163900.0  ...   \n",
       "636145    GA   20070430    292300.0  ...   \n",
       "636146    GA   20070831    181000.0  ...   \n",
       "636147    GA   20070214    179800.0  ...   \n",
       "636148    GA   20070420    185000.0  ...   \n",
       "\n",
       "                              publicremarks_vaderpolarity  \\\n",
       "0       {'compound': 0.9627, 'neg': 0.0, 'neu': 0.86, ...   \n",
       "1       {'compound': 0.9939, 'neg': 0.015, 'neu': 0.70...   \n",
       "2       {'compound': 0.8528, 'neg': 0.0, 'neu': 0.893,...   \n",
       "3       {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...   \n",
       "4       {'compound': 0.8829, 'neg': 0.0, 'neu': 0.877,...   \n",
       "...                                                   ...   \n",
       "636144  {'compound': 0.7684, 'neg': 0.0, 'neu': 0.832,...   \n",
       "636145  {'compound': 0.8741, 'neg': 0.0, 'neu': 0.764,...   \n",
       "636146  {'compound': 0.8779, 'neg': 0.0, 'neu': 0.684,...   \n",
       "636147  {'compound': 0.6341, 'neg': 0.0, 'neu': 0.881,...   \n",
       "636148  {'compound': 0.9613, 'neg': 0.0, 'neu': 0.673,...   \n",
       "\n",
       "                        clean_publicremarks_vaderpolarity  \\\n",
       "0       {'compound': 0.9627, 'neg': 0.0, 'neu': 0.781,...   \n",
       "1       {'compound': 0.9898, 'neg': 0.013, 'neu': 0.70...   \n",
       "2       {'compound': 0.8221, 'neg': 0.0, 'neu': 0.853,...   \n",
       "3       {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...   \n",
       "4       {'compound': 0.8829, 'neg': 0.0, 'neu': 0.849,...   \n",
       "...                                                   ...   \n",
       "636144  {'compound': 0.6351, 'neg': 0.0, 'neu': 0.834,...   \n",
       "636145  {'compound': 0.8741, 'neg': 0.0, 'neu': 0.736,...   \n",
       "636146  {'compound': 0.8779, 'neg': 0.0, 'neu': 0.605,...   \n",
       "636147  {'compound': 0.6341, 'neg': 0.0, 'neu': 0.862,...   \n",
       "636148  {'compound': 0.939, 'neg': 0.0, 'neu': 0.658, ...   \n",
       "\n",
       "        clean_publicremarks_additional_words_vaderpolarity  \\\n",
       "0       {'compound': 0.9401, 'neg': 0.0, 'neu': 0.803,...    \n",
       "1       {'compound': 0.9876, 'neg': 0.015, 'neu': 0.70...    \n",
       "2       {'compound': 0.8221, 'neg': 0.0, 'neu': 0.851,...    \n",
       "3       {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...    \n",
       "4       {'compound': 0.8309, 'neg': 0.0, 'neu': 0.878,...    \n",
       "...                                                   ...    \n",
       "636144  {'compound': 0.6351, 'neg': 0.0, 'neu': 0.822,...    \n",
       "636145  {'compound': 0.8741, 'neg': 0.0, 'neu': 0.728,...    \n",
       "636146  {'compound': 0.8779, 'neg': 0.0, 'neu': 0.59, ...    \n",
       "636147  {'compound': 0.6341, 'neg': 0.0, 'neu': 0.857,...    \n",
       "636148  {'compound': 0.939, 'neg': 0.0, 'neu': 0.649, ...    \n",
       "\n",
       "                clean_publicremarks_nopunct_vaderpolarity  \\\n",
       "0       {'compound': 0.9578, 'neg': 0.0, 'neu': 0.786,...   \n",
       "1       {'compound': 0.9889, 'neg': 0.014, 'neu': 0.69...   \n",
       "2       {'compound': 0.8074, 'neg': 0.0, 'neu': 0.858,...   \n",
       "3       {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...   \n",
       "4       {'compound': 0.8658, 'neg': 0.0, 'neu': 0.857,...   \n",
       "...                                                   ...   \n",
       "636144  {'compound': 0.5574, 'neg': 0.0, 'neu': 0.85, ...   \n",
       "636145  {'compound': 0.8316, 'neg': 0.0, 'neu': 0.762,...   \n",
       "636146  {'compound': 0.8779, 'neg': 0.0, 'neu': 0.605,...   \n",
       "636147  {'compound': 0.5106, 'neg': 0.0, 'neu': 0.887,...   \n",
       "636148  {'compound': 0.9287, 'neg': 0.0, 'neu': 0.655,...   \n",
       "\n",
       "        clean_publicremarks_nopunct_additional_words_vaderpolarity  \\\n",
       "0       {'compound': 0.93, 'neg': 0.0, 'neu': 0.81, 'p...            \n",
       "1       {'compound': 0.9864, 'neg': 0.016, 'neu': 0.7,...            \n",
       "2       {'compound': 0.8074, 'neg': 0.0, 'neu': 0.855,...            \n",
       "3       {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...            \n",
       "4       {'compound': 0.802, 'neg': 0.0, 'neu': 0.886, ...            \n",
       "...                                                   ...            \n",
       "636144  {'compound': 0.5574, 'neg': 0.0, 'neu': 0.839,...            \n",
       "636145  {'compound': 0.8316, 'neg': 0.0, 'neu': 0.755,...            \n",
       "636146  {'compound': 0.8779, 'neg': 0.0, 'neu': 0.59, ...            \n",
       "636147  {'compound': 0.5106, 'neg': 0.0, 'neu': 0.883,...            \n",
       "636148  {'compound': 0.9287, 'neg': 0.0, 'neu': 0.646,...            \n",
       "\n",
       "                clean_publicremarks_stemmed_vaderpolarity  \\\n",
       "0       {'compound': 0.6486, 'neg': 0.0, 'neu': 0.936,...   \n",
       "1       {'compound': 0.9732, 'neg': 0.0, 'neu': 0.801,...   \n",
       "2       {'compound': 0.3182, 'neg': 0.0, 'neu': 0.958,...   \n",
       "3       {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...   \n",
       "4       {'compound': 0.5106, 'neg': 0.0, 'neu': 0.932,...   \n",
       "...                                                   ...   \n",
       "636144  {'compound': 0.5574, 'neg': 0.0, 'neu': 0.85, ...   \n",
       "636145  {'compound': 0.6249, 'neg': 0.0, 'neu': 0.864,...   \n",
       "636146  {'compound': 0.7506, 'neg': 0.0, 'neu': 0.748,...   \n",
       "636147  {'compound': 0.3612, 'neg': 0.0, 'neu': 0.912,...   \n",
       "636148  {'compound': 0.8481, 'neg': 0.0, 'neu': 0.773,...   \n",
       "\n",
       "        clean_publicremarks_stemmed_additional_words_vaderpolarity  \\\n",
       "0       {'compound': 0.4939, 'neg': 0.0, 'neu': 0.954,...            \n",
       "1       {'compound': 0.9686, 'neg': 0.0, 'neu': 0.799,...            \n",
       "2       {'compound': 0.3182, 'neg': 0.0, 'neu': 0.957,...            \n",
       "3       {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...            \n",
       "4       {'compound': 0.2023, 'neg': 0.0, 'neu': 0.969,...            \n",
       "...                                                   ...            \n",
       "636144  {'compound': 0.5574, 'neg': 0.0, 'neu': 0.839,...            \n",
       "636145  {'compound': 0.6249, 'neg': 0.0, 'neu': 0.859,...            \n",
       "636146  {'compound': 0.7506, 'neg': 0.0, 'neu': 0.738,...            \n",
       "636147  {'compound': 0.3612, 'neg': 0.0, 'neu': 0.909,...            \n",
       "636148  {'compound': 0.8481, 'neg': 0.0, 'neu': 0.767,...            \n",
       "\n",
       "             clean_publicremarks_lemmatized_vaderpolarity  \\\n",
       "0       {'compound': 0.9578, 'neg': 0.0, 'neu': 0.786,...   \n",
       "1       {'compound': 0.9875, 'neg': 0.014, 'neu': 0.70...   \n",
       "2       {'compound': 0.8074, 'neg': 0.0, 'neu': 0.858,...   \n",
       "3       {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...   \n",
       "4       {'compound': 0.802, 'neg': 0.0, 'neu': 0.876, ...   \n",
       "...                                                   ...   \n",
       "636144  {'compound': 0.5574, 'neg': 0.0, 'neu': 0.85, ...   \n",
       "636145  {'compound': 0.8316, 'neg': 0.0, 'neu': 0.762,...   \n",
       "636146  {'compound': 0.8779, 'neg': 0.0, 'neu': 0.605,...   \n",
       "636147  {'compound': 0.5106, 'neg': 0.0, 'neu': 0.887,...   \n",
       "636148  {'compound': 0.9287, 'neg': 0.0, 'neu': 0.655,...   \n",
       "\n",
       "        clean_publicremarks_lemmatized_additional_words_vaderpolarity  \\\n",
       "0       {'compound': 0.93, 'neg': 0.0, 'neu': 0.81, 'p...               \n",
       "1       {'compound': 0.9844, 'neg': 0.016, 'neu': 0.70...               \n",
       "2       {'compound': 0.8074, 'neg': 0.0, 'neu': 0.855,...               \n",
       "3       {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos...               \n",
       "4       {'compound': 0.6908, 'neg': 0.0, 'neu': 0.908,...               \n",
       "...                                                   ...               \n",
       "636144  {'compound': 0.5574, 'neg': 0.0, 'neu': 0.839,...               \n",
       "636145  {'compound': 0.8316, 'neg': 0.0, 'neu': 0.755,...               \n",
       "636146  {'compound': 0.8779, 'neg': 0.0, 'neu': 0.59, ...               \n",
       "636147  {'compound': 0.5106, 'neg': 0.0, 'neu': 0.883,...               \n",
       "636148  {'compound': 0.9287, 'neg': 0.0, 'neu': 0.646,...               \n",
       "\n",
       "                                     sentence_composition  \n",
       "0       [63.74999999999999, 20.0, 21.25, 1.25, 1.25, 1...  \n",
       "1       [47.22222222222222, 14.814814814814813, 15.740...  \n",
       "2       [96.22641509433963, 30.18867924528302, 32.0754...  \n",
       "3       [392.30769230769226, 123.07692307692308, 130.7...  \n",
       "4       [83.60655737704919, 26.229508196721312, 27.868...  \n",
       "...                                                   ...  \n",
       "636144  [182.14285714285714, 57.14285714285714, 60.714...  \n",
       "636145  [188.88888888888889, 59.25925925925925, 62.962...  \n",
       "636146  [242.85714285714283, 76.19047619047619, 80.952...  \n",
       "636147  [170.0, 53.333333333333336, 56.666666666666664...  \n",
       "636148  [170.0, 53.333333333333336, 56.666666666666664...  \n",
       "\n",
       "[636149 rows x 72 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['transaction_year'] = np.floor(np.array((df_sales['Transdate'].values/10000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'listingid', 'asgpropid', 'qtr', 'tax_year', 'cbsa_div',\n",
       "       'cbsa', 'state', 'Transdate', 'Transprice', 'bedrooms', 'total_value',\n",
       "       'cj_living_area', 'basement', 'has_pool', 'parking', 'is_poor',\n",
       "       'is_good', 'HAS_VIEW', 'has_golf', 'has_water', 'has_woods', 'has_hill',\n",
       "       'fips_code', 'census_tract', 'zip', 'effective_year_built', 'story',\n",
       "       'ListingPrice', 'publicremarks', 'avmValue', 'avmerror', 'rentsale',\n",
       "       'publicremarks_prepared', 'publicremarks_prepared_spellcheck',\n",
       "       'publicremarks_prepared_unicode', 'clean_publicremarks',\n",
       "       'clean_publicremarks_additional_words', 'clean_publicremarks_nopunct',\n",
       "       'clean_publicremarks_nopunct_additional_words',\n",
       "       'clean_publicremarks_stemmed',\n",
       "       'clean_publicremarks_stemmed_additional_words',\n",
       "       'clean_publicremarks_lemmatized',\n",
       "       'clean_publicremarks_lemmatized_additional_words',\n",
       "       'publicremarks_nltkpolarity', 'clean_publicremarks_nltkpolarity',\n",
       "       'clean_publicremarks_additional_words_nltkpolarity',\n",
       "       'clean_publicremarks_nopunct_nltkpolarity',\n",
       "       'clean_publicremarks_nopunct_additional_words_nltkpolarity',\n",
       "       'clean_publicremarks_stemmed_nltkpolarity',\n",
       "       'clean_publicremarks_stemmed_additional_words_nltkpolarity',\n",
       "       'clean_publicremarks_lemmatized_nltkpolarity',\n",
       "       'clean_publicremarks_lemmatized_additional_words_nltkpolarity',\n",
       "       'publicremarks_textblobpolarity',\n",
       "       'clean_publicremarks_textblobpolarity',\n",
       "       'clean_publicremarks_additional_words_textblobpolarity',\n",
       "       'clean_publicremarks_nopunct_textblobpolarity',\n",
       "       'clean_publicremarks_nopunct_additional_words_textblobpolarity',\n",
       "       'clean_publicremarks_stemmed_textblobpolarity',\n",
       "       'clean_publicremarks_stemmed_additional_words_textblobpolarity',\n",
       "       'clean_publicremarks_lemmatized_textblobpolarity',\n",
       "       'clean_publicremarks_lemmatized_additional_words_textblobpolarity',\n",
       "       'publicremarks_vaderpolarity', 'clean_publicremarks_vaderpolarity',\n",
       "       'clean_publicremarks_additional_words_vaderpolarity',\n",
       "       'clean_publicremarks_nopunct_vaderpolarity',\n",
       "       'clean_publicremarks_nopunct_additional_words_vaderpolarity',\n",
       "       'clean_publicremarks_stemmed_vaderpolarity',\n",
       "       'clean_publicremarks_stemmed_additional_words_vaderpolarity',\n",
       "       'clean_publicremarks_lemmatized_vaderpolarity',\n",
       "       'clean_publicremarks_lemmatized_additional_words_vaderpolarity',\n",
       "       'sentence_composition', 'transaction_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006.0\n",
      "2021.0\n"
     ]
    }
   ],
   "source": [
    "print(df_sales['transaction_year'].min())\n",
    "print(df_sales['transaction_year'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'bigrams_join',\n",
       " 'count_n_grams',\n",
       " 'defaultdict',\n",
       " 'df_get_n_grams_count',\n",
       " 'df_lambda_ngram',\n",
       " 'generate_n_grams',\n",
       " 'get_imp',\n",
       " 'get_n_grams_count',\n",
       " 'get_n_grams_probability',\n",
       " 'kg',\n",
       " 'ngrams',\n",
       " 'np',\n",
       " 'pd',\n",
       " 'text']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlp_pandas_functions import ngram_analysis\n",
    "reload(ngram_analysis)\n",
    "dir(ngram_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_grams_probability(strtext, ngram, ngram_df):\n",
    "    df_ngram = ngram_analysis.get_n_grams_count(strtext,ngram)\n",
    "    df_ngram = df_ngram.rename({0: 'ngram', 1: 'count'}, axis='columns')\n",
    "    df_process = pd.merge(df_ngram, ngram_df, on=[\"ngram\"])\n",
    "    df_process['probability_mult'] = df_process['probability'] * df_process['count_x']\n",
    "    mean_prob =  (df_process['probability_mult'].sum() / df_process['count_x'].sum())\n",
    "    ngram_probs = list(df_process['probability'].quantile([.99, 0.95, 0.9, 0.75, 0.5, 0.25]))\n",
    "    ngram_probs.append(mean_prob)\n",
    "    return ngram_probs, df_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publicremarks\n",
      "Reading.. 34.28101099999999\n"
     ]
    }
   ],
   "source": [
    "columns = ['publicremarks', 'clean_publicremarks', 'clean_publicremarks_additional_words',\n",
    "          'clean_publicremarks_nopunct', 'clean_publicremarks_nopunct_additional_words',\n",
    "           'clean_publicremarks_stemmed', 'clean_publicremarks_stemmed_additional_words', \n",
    "           'clean_publicremarks_lemmatized', 'clean_publicremarks_lemmatized_additional_words'\n",
    "           ]\n",
    "\n",
    "suffix_1 = ['_ngram_probs_1_99', '_ngram_probs_1_95', '_ngram_probs_1_90', \n",
    "            '_ngram_probs_1_75', '_ngram_probs_1_50', '_ngram_probs_1_25', '_ngram_probs_1_MN']\n",
    "suffix_2 = ['_ngram_probs_2_99', '_ngram_probs_2_95', '_ngram_probs_2_90', \n",
    "            '_ngram_probs_2_75', '_ngram_probs_2_50', '_ngram_probs_2_25', '_ngram_probs_2_MN']\n",
    "suffix_3 = ['_ngram_probs_3_99', '_ngram_probs_3_95', '_ngram_probs_3_90', \n",
    "            '_ngram_probs_3_75', '_ngram_probs_3_50', '_ngram_probs_3_25', '_ngram_probs_3_MN']\n",
    "suffix_4 = ['_ngram_probs_4_99', '_ngram_probs_4_95', '_ngram_probs_4_90', \n",
    "            '_ngram_probs_4_75', '_ngram_probs_4_50', '_ngram_probs_4_25', '_ngram_probs_4_MN']\n",
    "\n",
    "\n",
    "for column in columns:\n",
    "    print(column)\n",
    "    \n",
    "    tic = time.clock()\n",
    "    unigram_df = pd.read_feather('ngrams/' + file + '_withsentiment_' + column + '_unigram.fea')\n",
    "    bigram_df = pd.read_feather('ngrams/' + file + '_withsentiment_' + column + '_bigram.fea')\n",
    "    trigram_df = pd.read_feather('ngrams/' + file + '_withsentiment_' + column + '_trigram.fea')\n",
    "    fourgram_df = pd.read_feather('ngrams/' + file + '_withsentiment_' + column + '_fourgram.fea')\n",
    "    \n",
    "    toc_r = time.clock()\n",
    "    print('Reading..',toc_r - tic)\n",
    "    \n",
    "    ngram_probs_array_uni = np.zeros([len(df_sales), 7])  \n",
    "    ngram_probs_array_bi = np.zeros([len(df_sales), 7])\n",
    "    ngram_probs_array_tri = np.zeros([len(df_sales), 7])\n",
    "    ngram_probs_array_four = np.zeros([len(df_sales), 7])\n",
    "    \n",
    "    column_names_1 = []\n",
    "    for cn in suffix_1:\n",
    "        column_names_1.append(column + cn)\n",
    "        \n",
    "    column_names_2 = []\n",
    "    for cn in suffix_2:\n",
    "        column_names_2.append(column + cn)\n",
    "        \n",
    "    column_names_3 = []\n",
    "    for cn in suffix_3:\n",
    "        column_names_3.append(column + cn)\n",
    "        \n",
    "    column_names_4 = []\n",
    "    for cn in suffix_4:\n",
    "        column_names_4.append(column + cn)\n",
    "        \n",
    "    for house in df_sales.index:\n",
    "        ngram_probs, df_process = get_n_grams_probability(df_sales[column][house], \n",
    "                                                          1, unigram_df)\n",
    "        ngram_probs_array_uni[house, :] = ngram_probs\n",
    "\n",
    "        ngram_probs, df_process = get_n_grams_probability(df_sales[column][house], \n",
    "                                                          2, bigram_df)\n",
    "        ngram_probs_array_bi[house, :] = ngram_probs\n",
    "\n",
    "        ngram_probs, df_process = get_n_grams_probability(df_sales[column][house], \n",
    "                                                          3, trigram_df)\n",
    "        ngram_probs_array_tri[house, :] = ngram_probs\n",
    "                \n",
    "        ngram_probs, df_process = get_n_grams_probability(df_sales[column][house], \n",
    "                                                          4, fourgram_df)\n",
    "        ngram_probs_array_four[house, :] = ngram_probs \n",
    "\n",
    "    for cid, colum_id in enumerate(column_names_3):\n",
    "        df_sales[colum_id] = ngram_probs_array_tri[:, cid].tolist() \n",
    "        \n",
    "    for cid, colum_id in enumerate(column_names_1):\n",
    "        df_sales[colum_id] = ngram_probs_array_uni[:, cid].tolist()   \n",
    "\n",
    "    for cid, colum_id in enumerate(column_names_2):\n",
    "        df_sales[colum_id] = ngram_probs_array_bi[:, cid].tolist() \n",
    "\n",
    "    for cid, colum_id in enumerate(column_names_4):\n",
    "        df_sales[colum_id] = ngram_probs_array_four[:, cid].tolist() \n",
    "        \n",
    "    toc = time.clock()\n",
    "    print(toc - tic)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.to_feather(file + '_withsentiment_sentencecomposition_' + 'ngram_probability' + '.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales[column][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'clean_publicremarks_nopunct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_df = pd.read_feather('ngrams/' + file + '_withsentiment_' + column + '_unigram.fea')\n",
    "bigram_df = pd.read_feather('ngrams/' + file + '_withsentiment_' + column + '_bigram.fea')\n",
    "trigram_df = pd.read_feather('ngrams/' + file + '_withsentiment_' + column + '_trigram.fea')\n",
    "fourgram_df = pd.read_feather('ngrams/' + file + '_withsentiment_' + column + '_fourgram.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigram_df[unigram_df['ngram'] == 'house']['probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "house = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say hello to this beautiful 4 bed 3 bath home located in desirable Armuchee. It has been recently updated with a farmhouse style. You will find white cabinets & an open concept with a breakfast bar. Down the hall is your cozy master with a sliding barn door & en suite with garden tub! Downstairs features a large room, walk in closet & bath that could be used as an in-law suite. You?ll love entertaining guests & watching your kids play in this privacy fenced in backyard. This home is the perfect place for your family to call their own so dont sleep on it sleep in it!\n",
      "160000.0\n",
      "170178.66\n",
      "160000.0\n",
      "-0.0636166250000001\n",
      "-0.06361662500000002\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(df_sales['publicremarks'].values[house])\n",
    "print(df_sales['ListingPrice'].values[house])\n",
    "print(df_sales['avmValue'].values[house])\n",
    "print(df_sales['Transprice'].values[house])\n",
    "print(df_sales['avmerror'].values[house])\n",
    "print((df_sales['Transprice'].values[house]-(df_sales['avmValue'].values[house]))/df_sales['Transprice'].values[house])\n",
    "print((df_sales['Transprice'].values[house]-(df_sales['ListingPrice'].values[house]))/df_sales['Transprice'].values[house])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'say hello beautiful digit bed digit bath home located desirable armuchee recently updated farmhouse style find white cabinets  open concept breakfast bar hall cozy master sliding barn door  en suite garden tub downstairs features large room walk closet  bath could used inlaw suite youll love entertaining guests  watching kids play privacy fenced backyard home perfect place family call dont sleep sleep it'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales['clean_publicremarks_nopunct'].values[house]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "listtemp, df_process = get_n_grams_probability(df_sales['clean_publicremarks_nopunct'].values[house], 2, bigram_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>count_x</th>\n",
       "      <th>count_y</th>\n",
       "      <th>probability</th>\n",
       "      <th>probability_mult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>say hello</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1.872678e-06</td>\n",
       "      <td>1.872678e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>hello beautiful</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3.322492e-07</td>\n",
       "      <td>3.322492e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>beautiful digit</td>\n",
       "      <td>1</td>\n",
       "      <td>13268</td>\n",
       "      <td>4.007530e-04</td>\n",
       "      <td>4.007530e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>digit bed</td>\n",
       "      <td>1</td>\n",
       "      <td>11040</td>\n",
       "      <td>3.334574e-04</td>\n",
       "      <td>3.334574e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>bed digit</td>\n",
       "      <td>1</td>\n",
       "      <td>7162</td>\n",
       "      <td>2.163245e-04</td>\n",
       "      <td>2.163245e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>family call</td>\n",
       "      <td>1</td>\n",
       "      <td>213</td>\n",
       "      <td>6.433553e-06</td>\n",
       "      <td>6.433553e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>call dont</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.208179e-07</td>\n",
       "      <td>1.208179e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>dont sleep</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1.359201e-06</td>\n",
       "      <td>1.359201e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>sleep sleep</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.061343e-08</td>\n",
       "      <td>9.061343e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>sleep it</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1.057157e-06</td>\n",
       "      <td>1.057157e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ngram  count_x  count_y   probability  probability_mult\n",
       "0         say hello        1       62  1.872678e-06      1.872678e-06\n",
       "1   hello beautiful        1       11  3.322492e-07      3.322492e-07\n",
       "2   beautiful digit        1    13268  4.007530e-04      4.007530e-04\n",
       "3         digit bed        1    11040  3.334574e-04      3.334574e-04\n",
       "4         bed digit        1     7162  2.163245e-04      2.163245e-04\n",
       "..              ...      ...      ...           ...               ...\n",
       "56      family call        1      213  6.433553e-06      6.433553e-06\n",
       "57        call dont        1        4  1.208179e-07      1.208179e-07\n",
       "58       dont sleep        1       45  1.359201e-06      1.359201e-06\n",
       "59      sleep sleep        1        3  9.061343e-08      9.061343e-08\n",
       "60         sleep it        1       35  1.057157e-06      1.057157e-06\n",
       "\n",
       "[61 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[.99, 0.95, 0.9, 0.75, 0.5, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0012909151340009483,\n",
       " 0.0009336203483445954,\n",
       " 0.0006589408450173307,\n",
       " 0.00017727006872968068,\n",
       " 2.5734213419268692e-05,\n",
       " 1.480019316366392e-06,\n",
       " 0.00017401986906670676]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listtemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_analysis.get_n_grams_count(df_sales['clean_publicremarks_nopunct'].values[house],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process.probability.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process.probability.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_df = unigram_df.rename({0: 'ngram', 1: 'count'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
